{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "8b       720\n",
       "70b      720\n",
       "405B     720\n",
       "flash    720\n",
       "pro      720\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DROP datasets\n",
    "df_8b = pd.read_csv('/Users/log/Downloads/fs_inst_llama_sambanova_8b_temp_10_full.csv')\n",
    "df_8b['model'] = '8b'\n",
    "df_70b = pd.read_csv('/Users/log/Downloads/fs_inst_llama_sambanova_70b_temp_10_longest (5).csv')\n",
    "df_70b['model'] = '70b'\n",
    "df_405B = pd.read_csv('/Users/log/Downloads/fs_inst_llama_sambanova_405b_temp_10_longest (6).csv')\n",
    "df_405B['model'] = '405B'\n",
    "df_flash = pd.read_csv('/Users/log/Downloads/fs_inst_gemini-1.5-flash-002_temp_10_longest (4).csv')\n",
    "df_flash['model'] = 'flash'\n",
    "df_pro = pd.read_csv('/Users/log/Downloads/fs_inst_gemini-1.5-pro-002_temp_10_longest (2).csv')\n",
    "df_pro['model'] = 'pro'\n",
    "\n",
    "drop_responses = pd.concat([df_8b, df_70b, df_405B, df_flash, df_pro])\n",
    "\n",
    "# models = df_combined['model'].unique().tolist()  # Explicit order if needed\n",
    "\n",
    "# selected_ids = set()\n",
    "# result_dfs = []\n",
    "\n",
    "# for model in models:\n",
    "#     # Filter current model's entries not already selected\n",
    "#     available = df_combined[(df_combined['model'] == model) & (~df_combined['id'].isin(selected_ids))]\n",
    "    \n",
    "#     # Sample 100 unique IDs\n",
    "#     sampled = available.drop_duplicates(subset='id').sample(n=50, random_state=42)  # Adjust random_state if needed\n",
    "    \n",
    "#     if len(sampled) < 50:\n",
    "#         raise ValueError(f\"Model {model} lacks 100 unique IDs after removing overlaps.\")\n",
    "    \n",
    "#     # Update selected IDs and store results\n",
    "#     selected_ids.update(sampled['id'].tolist())\n",
    "#     result_dfs.append(sampled)\n",
    "\n",
    "# # Combine results and verify\n",
    "# drop_responses = pd.concat(result_dfs, ignore_index=True)\n",
    "# assert drop_responses['id'].nunique() == 250, \"Duplicate IDs detected in final selection.\"\n",
    "\n",
    "# drop_df['id'].value_counts()\n",
    "# drop_df.columns()\n",
    "drop_responses\n",
    "drop_responses['model'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isTrue\n",
      "True     2437\n",
      "False     333\n",
      "Name: count, dtype: int64\n",
      "Model: 405B\n",
      "isTrue\n",
      "True     525\n",
      "False     29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: 70b\n",
      "isTrue\n",
      "True     498\n",
      "False     56\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: 8b\n",
      "isTrue\n",
      "True     422\n",
      "False    132\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: flash\n",
      "isTrue\n",
      "True     485\n",
      "False     69\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: pro\n",
      "isTrue\n",
      "True     507\n",
      "False     47\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonl_path = '/Users/log/Github/textual_grounding/data/drop_break/test.jsonl'\n",
    "data = pd.read_json(jsonl_path, lines=True)\n",
    "df_drop = pd.DataFrame(columns=['id', 'question', 'model', 'answer', 'gt_number', 'isTrue'])\n",
    "\n",
    "\n",
    "def extract_answer(text):\n",
    "    pattern = re.compile(r\"\\{([-]?[0-9,]*\\.?[0-9]+)\\}\")\n",
    "    match = pattern.search(str(text))\n",
    "    num_str = match.group(1) if match else \"-99999999999999\"\n",
    "    num_str_clean = num_str.replace(',', '')  # '9759417'\n",
    "    numeric_value = float(num_str_clean)      # 9759417.0 (float)\n",
    "    return numeric_value\n",
    "\n",
    "for idx, row in drop_responses.iterrows():\n",
    "    response_text = row['answer']\n",
    "    \n",
    "    # Compare to ground-truth\n",
    "    gt_row = data.loc[data['id'] == row['id']]\n",
    "    gt_answer = gt_row['answer'].iloc[0]  # or answer[0], etc.\n",
    "    \n",
    "    if len(gt_answer) > 1:\n",
    "        continue\n",
    "    extracted_answer = extract_answer(response_text)\n",
    "    # print(f\"ID: {row['id']}\")\n",
    "    # print(f\"Model Answer Text: {response_text}\")\n",
    "    # print(f\"Extracted numeric answer: {extracted_answer}\")\n",
    "    # gt_number = float(gt_answer[-1][0])  # 54.4\n",
    "    # if extracted_answer == -99999999999999:\n",
    "    #     continue\n",
    "    gt1 = str(gt_answer[0][0])\n",
    "    # gt2 = \"\"\n",
    "    # if len(gt_answer) == 2:\n",
    "    #     gt2 = str(gt_answer[1][0])\n",
    "    # gt_number = gt1 + \" \" + gt2\n",
    "    gt_number = gt1\n",
    "    row['gt_number'] = float(gt_number)\n",
    "    # mismatched_rows = pd.concat([mismatched_rows, row.to_frame().T], ignore_index=True)\n",
    "    # print(f\"Ground-truth answer: {gt_number}\")\n",
    "    # print(\"----\")\n",
    "    \n",
    "    \n",
    "    # Check if the extracted answer matches the ground-truth\n",
    "    # print(extracted_answer, gt_number)\n",
    "    # if extracted_answer == gt_number:\n",
    "    strip_ans = row['answer'].replace(',', '').replace('.', '').replace('$', '')\n",
    "    # if abs(float(extracted_answer) - float(gt_number)) <= 0.00001:\n",
    "    # print(str(int(row['gt_number'])))\n",
    "    row['extract_answer'] = extracted_answer\n",
    "    row['gt_number'] = gt_number\n",
    "    if str(float(row['gt_number'])) not in strip_ans[-80::] and str(int(float(row['gt_number']))) not in strip_ans[-80::] and abs(float(extracted_answer) - float(gt_number)) > 0.1:\n",
    "        # if extracted_answer == -99999999999999 and row['id'] not in good_questions:\n",
    "        # print(row['answer'])\n",
    "        # print(gt_number)\n",
    "        # print()\n",
    "            # continue\n",
    "        # if abs(float(extracted_answer) - float(gt_number)) <= 0.001:\n",
    "        #     continue\n",
    "        row['isTrue'] = False\n",
    "\n",
    "        # if row['id'] in good_questions:\n",
    "        #     print(row['id'])\n",
    "        df_drop = pd.concat([df_drop, row.to_frame().T], ignore_index=True)\n",
    "    # if abs(float(extracted_answer) - float(gt_number)) < 0.1: # correct answer\n",
    "    else:\n",
    "        # print('aoeuaoe')\n",
    "        row['isTrue'] = True\n",
    "        df_drop = pd.concat([df_drop, row.to_frame().T], ignore_index=True)\n",
    "    #     mismatched_rows = pd.concat([mismatched_rows, row.to_frame().T], ignore_index=True)\n",
    "    # if extracted_answer == gt_number: # correct\n",
    "    #     row['gt_number'] = gt_number\n",
    "    #     mismatched_rows = pd.concat([mismatched_rows, row.to_frame().T], ignore_index=True)\n",
    "\n",
    "# print(df_drop.head())\n",
    "print(df_drop['isTrue'].value_counts())\n",
    "# print(df_drop['model'].value_counts())\n",
    "\n",
    "for model, group in df_drop.groupby('model'):\n",
    "    print(f\"Model: {model}\")\n",
    "    print(group['isTrue'].value_counts())\n",
    "    print(\"\\n\")  # Add a newline for better readability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need 250 drop responses\n",
    "\n",
    "50 responses per model\n",
    "25 true 25 false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 405B\n",
      "25 pro\n",
      "25 70b\n",
      "25 flash\n",
      "25 8b\n",
      "isTrue\n",
      "True     125\n",
      "False    125\n",
      "Name: count, dtype: int64\n",
      "model\n",
      "405B     50\n",
      "pro      50\n",
      "70b      50\n",
      "flash    50\n",
      "8b       50\n",
      "Name: count, dtype: int64\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame to store the final results\n",
    "final_df = pd.DataFrame(columns=['id', 'question', 'model', 'answer', 'gt_number', 'isTrue'])\n",
    "\n",
    "# Track used IDs to ensure uniqueness across all models\n",
    "used_ids = set()\n",
    "models = ['405B', 'pro', '70b', 'flash', '8b']\n",
    "\n",
    "# Iterate over each model\n",
    "for model in models:\n",
    "    # Filter the DataFrame for the current model\n",
    "    model_df = df_drop[df_drop['model'] == model]\n",
    "    \n",
    "    # Separate true and false responses\n",
    "    true_responses = model_df[model_df['isTrue'] == True]\n",
    "    false_responses = model_df[model_df['isTrue'] == False]\n",
    "    \n",
    "    # Filter out IDs that have already been used\n",
    "    true_responses = true_responses[~true_responses['id'].isin(used_ids)]\n",
    "    false_responses = false_responses[~false_responses['id'].isin(used_ids)]\n",
    "    \n",
    "    # Sample 25 true and 25 false responses, ensuring unique IDs\n",
    "    sampled_true = true_responses.drop_duplicates(subset=['id']).sample(n=25, random_state=1)\n",
    "    print(len(sampled_false), model)\n",
    "    try:\n",
    "        sampled_false = false_responses.drop_duplicates(subset=['id']).sample(n=25, random_state=1)\n",
    "    except:\n",
    "        sampled_false = false_responses.sample(n=25, random_state=1)\n",
    "        # print('aaa')\n",
    "    \n",
    "    # Add the sampled IDs to the used_ids set\n",
    "    used_ids.update(sampled_true['id'].tolist())\n",
    "    used_ids.update(sampled_false['id'].tolist())\n",
    "    \n",
    "    # Combine the sampled responses\n",
    "    sampled_responses = pd.concat([sampled_true, sampled_false])\n",
    "    \n",
    "    # Append to the final DataFrame\n",
    "    final_df = pd.concat([final_df, sampled_responses])\n",
    "\n",
    "# Reset the index of the final DataFrame\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check the final DataFrame\n",
    "print(final_df['isTrue'].value_counts())\n",
    "print(final_df['model'].value_counts())\n",
    "\n",
    "# Verify that all IDs are unique\n",
    "print(final_df['id'].nunique())\n",
    "# assert final_df['id'].nunique() == final_df.shape[0], \"There are duplicate IDs in the final DataFrame.\"\n",
    "final_df.drop(columns=['extract_answer', 'question'], inplace=True)\n",
    "final_df.rename(columns={'gt_number': 'gt'}, inplace=True)\n",
    "final_df['unique_id'] = final_df['id']\n",
    "\n",
    "# Save the final DataFrame to a CSV file if needed\n",
    "final_df.to_csv('sampled_DROP_responses.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 405B\n",
      "isTrue\n",
      "True     25\n",
      "False    25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: 70b\n",
      "isTrue\n",
      "True     25\n",
      "False    25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: 8b\n",
      "isTrue\n",
      "True     25\n",
      "False    25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: flash\n",
      "isTrue\n",
      "True     25\n",
      "False    25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: pro\n",
      "isTrue\n",
      "True     25\n",
      "False    25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model, group in final_df.groupby('model'):\n",
    "    print(f\"Model: {model}\")\n",
    "    print(group['isTrue'].value_counts())\n",
    "    print(\"\\n\")  # Add a newline for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main split\n",
    "df_8b_incorrect = pd.read_csv('/Users/log/Github/textual_grounding/logan/SYMBOLIC_data/8b_main_incorrect_responses.csv')\n",
    "df_8b_incorrect['model'] = '8b'\n",
    "df_8b_correct = pd.read_csv('/Users/log/Github/textual_grounding/logan/SYMBOLIC_data/8b_main_correct_responses.csv')\n",
    "df_8b_correct['model'] = '8b'\n",
    "\n",
    "# df_flash_incorrect = pd.read_csv('/Users/log/Github/textual_grounding/logan/SYMBOLIC_data/gflash_main_incorrect_responses.csv')\n",
    "# df_flash_incorrect['model'] = 'flash'\n",
    "# df_flash_correct = pd.read_csv('/Users/log/Github/textual_grounding/logan/SYMBOLIC_data/gflash_main_correct_responses.csv')\n",
    "# df_flash_correct['model'] = 'flash'\n",
    "\n",
    "df_70b_incorrect = pd.read_csv('/Users/log/Github/textual_grounding/logan/SYMBOLIC_data/70b_main_incorrect_responses.csv')\n",
    "df_70b_incorrect['model'] = '70b'\n",
    "df_70b_correct = pd.read_csv('/Users/log/Github/textual_grounding/logan/SYMBOLIC_data/70b_main_correct_responses.csv')\n",
    "df_70b_correct['model'] = '70b'\n",
    "\n",
    "\n",
    "df_main = pd.concat([df_8b_incorrect, df_8b_correct, df_70b_incorrect, df_70b_correct])\n",
    "\n",
    "# p2 split\n",
    "\n",
    "df_405B_incorrect = pd.read_csv('/Users/log/Github/textual_grounding/logan/SYMBOLIC_data/405b_p2_incorrect_responses.csv')\n",
    "df_405B_incorrect['model'] = '405B'\n",
    "df_405B_correct = pd.read_csv('/Users/log/Github/textual_grounding/logan/SYMBOLIC_data/405b_p2_correct_responses.csv')\n",
    "df_405B_correct['model'] = '405B'\n",
    "\n",
    "df_pro = pd.read_csv('/Users/log/Github/textual_grounding/logan/SYMBOLIC_data/gemini_pro_p2_subset.csv')\n",
    "df_pro['model'] = 'pro'\n",
    "# print(df_pro['id'].value_counts())\n",
    "# print(df_pro['id'].nunique())\n",
    "\n",
    "df_flash = pd.read_csv('/Users/log/Github/textual_grounding/logan/SYMBOLIC_data/gemini_flash_p2_subset.csv')\n",
    "df_flash['model'] = 'flash'\n",
    "\n",
    "\n",
    "df_p2 = pd.concat([df_405B_incorrect, df_405B_correct, df_pro, df_flash])\n",
    "\n",
    "df_symbolic = pd.concat([df_main, df_p2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 405B\n",
      "isTrue\n",
      "1    1608\n",
      "0     201\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: 70b\n",
      "isTrue\n",
      "1    3522\n",
      "0     141\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: 8b\n",
      "isTrue\n",
      "1    1750\n",
      "0     325\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: flash\n",
      "isTrue\n",
      "1    201\n",
      "0     56\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Model: pro\n",
      "isTrue\n",
      "1    211\n",
      "0     52\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_symbolic['model'].value_counts()\n",
    "for model, group in df_symbolic.groupby('model'):\n",
    "    print(f\"Model: {model}\")\n",
    "    print(group['isTrue'].value_counts())\n",
    "    print(\"\\n\")  # Add a newline for better readability\n",
    "    \n",
    "# df_symbolic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false resposes length:  56\n",
      "false resposes length:  52\n",
      "isTrue\n",
      "1    125\n",
      "0    125\n",
      "Name: count, dtype: int64\n",
      "model\n",
      "8b       50\n",
      "70b      50\n",
      "flash    50\n",
      "pro      50\n",
      "405B     50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sampled_symbolic_main = pd.DataFrame(columns=['id', 'question', 'model', 'answer', 'gt_number', 'isTrue'])\n",
    "sampled_symbolic_gemini = pd.DataFrame(columns=['id', 'question', 'model', 'answer', 'gt_number', 'isTrue'])\n",
    "sampled_symbolic_p2 = pd.DataFrame(columns=['id', 'question', 'model', 'answer', 'gt_number', 'isTrue'])\n",
    "\n",
    "\n",
    "# Track used IDs to ensure uniqueness across all models\n",
    "used_unique_ids = set()\n",
    "used_p2_ids = set()\n",
    "\n",
    "models = ['flash', 'pro']\n",
    "\n",
    "# go through p2 split first\n",
    "# need unique_ids\n",
    "for model in models:\n",
    "    # Filter the DataFrame for the current model\n",
    "    model_df = df_symbolic[df_symbolic['model'] == model]\n",
    "    \n",
    "    # Separate true and false responses\n",
    "    true_responses = model_df[model_df['isTrue'] == True]\n",
    "    false_responses = model_df[model_df['isTrue'] == False]\n",
    "    \n",
    "    # Filter out IDs that have already been used\n",
    "    true_responses = true_responses[~true_responses['id'].isin(used_unique_ids)]\n",
    "    print(\"false resposes length: \", len(false_responses))\n",
    "\n",
    "    # false_responses = false_responses[~false_responses['id'].isin(used_unique_ids)]\n",
    "    \n",
    "    # Sample 25 true and 25 false responses, ensuring unique IDs\n",
    "    try:\n",
    "        sampled_true = true_responses.drop_duplicates(subset=['id']).sample(n=25, random_state=1)\n",
    "    except:\n",
    "        print(\"failed: \", model)\n",
    "        break\n",
    "    # try:\n",
    "    sampled_false = false_responses.drop_duplicates(subset=['unique_id']).sample(n=25, random_state=1)\n",
    "    # except:\n",
    "\n",
    "    # Add the sampled IDs to the used_ids set\n",
    "    used_unique_ids.update(sampled_true['unique_id'].tolist())\n",
    "    used_unique_ids.update(sampled_false['unique_id'].tolist())\n",
    "    used_p2_ids.update(sampled_true['id'].tolist())\n",
    "    used_p2_ids.update(sampled_false['id'].tolist())\n",
    "    \n",
    "    # Combine the sampled responses\n",
    "    sampled_responses = pd.concat([sampled_true, sampled_false])\n",
    "    \n",
    "    # Append to the final DataFrame\n",
    "    sampled_symbolic_gemini = pd.concat([sampled_symbolic_gemini, sampled_responses])\n",
    "\n",
    "models = ['405B']\n",
    "\n",
    "# need unique_ids\n",
    "for model in models:\n",
    "    # Filter the DataFrame for the current model\n",
    "    model_df = df_symbolic[df_symbolic['model'] == model]\n",
    "    \n",
    "    # Separate true and false responses\n",
    "    true_responses = model_df[model_df['isTrue'] == True]\n",
    "    false_responses = model_df[model_df['isTrue'] == False]\n",
    "    \n",
    "    # Filter out IDs that have already been used\n",
    "    true_responses = true_responses[~true_responses['id'].isin(used_p2_ids)]\n",
    "    # false_responses = false_responses[~false_responses['id'].isin(used_p2_ids)]\n",
    "    # print(len(false_responses))\n",
    "    \n",
    "    # Sample 25 true and 25 false responses, ensuring unique IDs\n",
    "    try:\n",
    "        sampled_true = true_responses.sample(n=25, random_state=1)\n",
    "    except:\n",
    "        print(\"failed: \", model)\n",
    "        break\n",
    "    sampled_false = false_responses.sample(n=25, random_state=1)\n",
    "    \n",
    "    # Add the sampled IDs to the used_ids set\n",
    "    used_unique_ids.update(sampled_true['unique_id'].tolist())\n",
    "    used_unique_ids.update(sampled_false['unique_id'].tolist())\n",
    "    used_p2_ids.update(sampled_true['id'].tolist())\n",
    "    used_p2_ids.update(sampled_false['id'].tolist())\n",
    "    \n",
    "    # Combine the sampled responses\n",
    "    sampled_responses = pd.concat([sampled_true, sampled_false])\n",
    "    \n",
    "    # Append to the final DataFrame\n",
    "    sampled_symbolic_p2 = pd.concat([sampled_symbolic_p2, sampled_responses])\n",
    "\n",
    "\n",
    "used_unique_ids = set()\n",
    "models = ['8b', '70b']\n",
    "# Iterate over each model\n",
    "for model in models:\n",
    "    # Filter the DataFrame for the current model\n",
    "    model_df = df_symbolic[df_symbolic['model'] == model]\n",
    "    \n",
    "    # Separate true and false responses\n",
    "    true_responses = model_df[model_df['isTrue'] == True]\n",
    "    false_responses = model_df[model_df['isTrue'] == False]\n",
    "    \n",
    "    # Filter out IDs that have already been used\n",
    "    # true_responses = true_responses[~true_responses['id'].isin(used_ids)]\n",
    "    # false_responses = false_responses[~false_responses['id'].isin(used_ids)]\n",
    "    \n",
    "    # Sample 25 true and 25 false responses, ensuring unique IDs\n",
    "    try:\n",
    "        sampled_true = true_responses.sample(n=25, random_state=1)\n",
    "    except:\n",
    "        print(\"failed: \", model)\n",
    "        break\n",
    "    sampled_false = false_responses.sample(n=25, random_state=1)\n",
    "    \n",
    "    # Add the sampled IDs to the used_ids set\n",
    "    used_ids.update(sampled_true['id'].tolist())\n",
    "    used_ids.update(sampled_false['id'].tolist())\n",
    "    \n",
    "    # Combine the sampled responses\n",
    "    sampled_responses = pd.concat([sampled_true, sampled_false])\n",
    "    \n",
    "    # Append to the final DataFrame\n",
    "    sampled_symbolic_main = pd.concat([sampled_symbolic_main, sampled_responses])\n",
    "\n",
    "sampled_symbolic = pd.concat([sampled_symbolic_main, sampled_symbolic_gemini, sampled_symbolic_p2])\n",
    "# Reset the index of the final DataFrame\n",
    "sampled_symbolic.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check the final DataFrame\n",
    "print(sampled_symbolic['isTrue'].value_counts())\n",
    "print(sampled_symbolic['model'].value_counts())\n",
    "\n",
    "sampled_symbolic.drop(columns=['gt_number', 'answer', 'question_len'], inplace=True)\n",
    "sampled_symbolic['dataset'] = 'symbolic'\n",
    "sampled_symbolic.to_csv('sampled_symbolic_responses.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'question', 'model', 'isTrue', 'gt', 'isTagged', 'dataset',\n",
      "       'unique_id'],\n",
      "      dtype='object')\n",
      "Index(['id', 'model', 'question', 'gt', 'isTrue', 'unique_id', 'isTagged',\n",
      "       'dataset'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "final_df['isTagged'] = True\n",
    "final_df['dataset'] = 'DROP'\n",
    "final_df['unique_id'] = final_df['id']\n",
    "final_df.rename(columns={'answer': 'question'}, inplace=True)\n",
    "sampled_symbolic['isTagged'] = True\n",
    "print(sampled_symbolic.columns)\n",
    "print(final_df.columns)\n",
    "\n",
    "\n",
    "tagged = pd.concat([final_df, sampled_symbolic])\n",
    "tagged['isTrue'] = tagged['isTrue'].astype(bool)\n",
    "tagged['isTrue'] = tagged['isTagged'].astype(bool)\n",
    "tagged.to_csv('tagged_responses.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
