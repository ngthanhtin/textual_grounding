{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "import sys\n",
    "import anthropic\n",
    "import ollama\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from google.generativeai.types import RequestOptions\n",
    "from google.api_core import retry\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import datetime\n",
    "import openai\n",
    "import time\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Shot - Vanilla CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_vanilla_cot = \"\"\"\n",
    "Think through your answer step by step. Put the concise form of your final answer in curly brackets e.g. {A}, {True} or {False}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(prompt_type: str, few_shot_prompt: str, question: str) -> str:\n",
    "    prompts = {\n",
    "        \"zero_shot_vanilla_cot\": f\"{question}\\n{zero_shot_vanilla_cot}\",\n",
    "    }\n",
    "    return prompts[prompt_type]\n",
    "\n",
    "def save_results(save_path: str, ids: List[str], questions: List[str], answers: List[str], append: bool = False):\n",
    "    df = pd.DataFrame({'id': ids, 'question': questions, 'answer': answers})\n",
    "    if append and os.path.exists(save_path):\n",
    "        df.to_csv(save_path, mode='a', index=False, header=False)\n",
    "    else:\n",
    "        df.to_csv(save_path, index=False)\n",
    "\n",
    "def read_jsonl_file(filepath: str) -> List[dict]:\n",
    "    data = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line)\n",
    "            data.append(json_obj)\n",
    "    return data\n",
    "\n",
    "def load_data_size_specific(data_path: str, sample_size: int = 0, random_seed: int = 0):\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    if data_path.endswith('.jsonl'):\n",
    "        data = read_jsonl_file(data_path)\n",
    "    elif data_path.endswith('.json'):\n",
    "        with open(data_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "    \n",
    "    question_length = 0\n",
    "    eligible_data = [x for x in data if len(x[\"question\"]) >= question_length]\n",
    "    \n",
    "    if sample_size > 0 and sample_size < len(eligible_data):\n",
    "        sampled_data = random.sample(eligible_data, sample_size)\n",
    "    else:\n",
    "        sampled_data = eligible_data\n",
    "    \n",
    "    ids = [x[\"id\"] for x in sampled_data]\n",
    "    questions = [x[\"question\"] for x in sampled_data]\n",
    "    \n",
    "    return ids, questions\n",
    "\n",
    "def load_already_answered_ids(save_path: str) -> set:\n",
    "    if os.path.exists(save_path):\n",
    "        df = pd.read_csv(save_path)\n",
    "        answered_ids = set(df['id'].tolist())\n",
    "        # print(f\"Loaded {len(answered_ids)} already answered IDs from: {save_path}\")\n",
    "        print(f\"Already answered IDs: {answered_ids}\")\n",
    "        return answered_ids\n",
    "    else:\n",
    "        print(f\"No existing save file found at: {save_path}. Starting fresh.\")\n",
    "        return set()\n",
    "\n",
    "def initialize_save_file(save_path: str):\n",
    "    if not os.path.exists(save_path):\n",
    "        # Create an empty DataFrame with headers and save\n",
    "        df = pd.DataFrame(columns=['id', 'question', 'answer'])\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"Initialized new save file with headers at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_4o(prompt: str) -> str:\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{prompt}\"\n",
    "            }\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def query_llama(prompt):\n",
    "    client = openai.OpenAI(\n",
    "        api_key=os.environ.get(\"SAMBANOVA_API_KEY\"),\n",
    "        base_url=\"https://api.sambanova.ai/v1\",\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='Meta-Llama-3.1-8B-Instruct',\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "        temperature=0.6, # Meta default\n",
    "        top_p = 0.9 # Meta default\n",
    "    )\n",
    "    time.sleep(2)  # Pause execution for 2 seconds\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def query_llama_70b(prompt):\n",
    "    client = openai.OpenAI(\n",
    "        api_key=os.environ.get(\"SAMBANOVA_API_KEY\"),\n",
    "        base_url=\"https://api.sambanova.ai/v1\",\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='Meta-Llama-3.1-70B-Instruct',\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ],\n",
    "        temperature=0.6, # Meta default\n",
    "        top_p = 0.9 # Meta default\n",
    "    )\n",
    "    time.sleep(2)  # Pause execution for 2 seconds\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(llm_model: str, ids: List[str], questions: List[str], few_shot_prompt: str, prompt_type: str, save_path: str, already_answered_ids: set) -> Tuple[List[str], List[str], List[str]]:\n",
    "    answers = []\n",
    "    ids_can_be_answered = []\n",
    "    questions_can_be_answered = []\n",
    "    \n",
    "    for id, q in tqdm(zip(ids, questions), total=len(ids)):\n",
    "        # print(q)\n",
    "        # print(f\"Processing ID: {id}\")\n",
    "        if id in already_answered_ids:\n",
    "            print(f\"Skipping: {id}\", end=' ')\n",
    "            continue\n",
    "        if id == 1146: # weird ID that breaks llama\n",
    "            continue\n",
    "        \n",
    "        prompt = get_prompt(prompt_type, few_shot_prompt, q)\n",
    "        try:\n",
    "            if llm_model == 'gemini':\n",
    "                answer = query_gemini(prompt, id)\n",
    "            elif llm_model == 'claude':\n",
    "                answer = query_claude(prompt)\n",
    "            elif llm_model == '4o':\n",
    "                # answer = query_4o_multiturn(prompt)\n",
    "                if prompt_type == 'multi_convo':\n",
    "                    fact_prompt = get_prompt(prompt_type=\"fact_prompt\", few_shot_prompt=\"\", question=q)\n",
    "                    \n",
    "                    answer_prompt = get_prompt(prompt_type=\"answer_prompt_data\", few_shot_prompt=\"\", question=q)\n",
    "                    answer = query_4o_multiconvo(fact_prompt=fact_prompt, answer_prompt=answer_prompt, extracted_question=q)\n",
    "                else:\n",
    "                    answer = query_4o(prompt)\n",
    "                \n",
    "            elif llm_model == 'llama3.18b':\n",
    "                answer = query_llama(prompt)\n",
    "            elif llm_model == 'llama3.170b':\n",
    "                answer = query_llama_70b(prompt)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported LLM model: {llm_model}\")\n",
    "            # print(f\"Answer for ID {id}: {answer}\")\n",
    "            \n",
    "            answers.append(answer)\n",
    "            questions_can_be_answered.append(q)\n",
    "            ids_can_be_answered.append(id)\n",
    "\n",
    "            # Save after each answer\n",
    "            save_results(save_path, [id], [q], [answer], append=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {id}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return ids_can_be_answered, questions_can_be_answered, answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_datasets = ['logical_deduction_seven_objects','reasoning_about_colored_objects', 'wikimultihopQA']\n",
    "jsonl_datasets = ['GSM8K', 'MultiArith', 'ASDiv', 'SVAMP', 'AQUA', 'p_GSM8K', 'StrategyQA', 'commonsenseQA','SPARTQA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(llm_model, prompt_type, few_shot_txt, sample_size, project_root):\n",
    "    for dataset in jsonl_datasets:\n",
    "        print(f\"------Processing dataset: {dataset}-------\")\n",
    "        if few_shot_txt:\n",
    "            fewshot_prompt_path = os.path.join(project_root, \"prompt\", dataset, few_shot_txt)\n",
    "            \n",
    "        save_dir = os.path.join(project_root, 'logan/results/final/VanillaCoT', dataset, f'{llm_model}')\n",
    "        os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists\n",
    "        save_path = os.path.join(save_dir, f'{prompt_type}_{few_shot_txt}_{dataset}_{llm_model}.csv')\n",
    "\n",
    "        if dataset in json_datasets:\n",
    "            data_path = os.path.join(project_root, 'data', dataset, 'test.json')\n",
    "        else:\n",
    "            data_path = os.path.join(project_root, 'data', dataset, 'test.jsonl')\n",
    "\n",
    "\n",
    "        ids, questions = load_data_size_specific(data_path, sample_size=sample_size)\n",
    "        if few_shot_txt:\n",
    "            with open(fewshot_prompt_path, 'r') as file:\n",
    "                few_shot_prompt = file.read()\n",
    "        else:\n",
    "            few_shot_prompt = \"\"\n",
    "\n",
    "        initialize_save_file(save_path)\n",
    "        already_answered_ids = load_already_answered_ids(save_path)\n",
    "\n",
    "        ids_answered, questions_answered, answers = query_llm(\n",
    "            llm_model=llm_model,\n",
    "            ids=ids,\n",
    "            questions=questions,\n",
    "            few_shot_prompt=few_shot_prompt,\n",
    "            prompt_type=prompt_type,\n",
    "            save_path=save_path,\n",
    "            already_answered_ids=already_answered_ids\n",
    "        )\n",
    "\n",
    "        print(f\"Processing complete for {dataset}. {len(ids_answered)} new answers saved to {save_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Processing dataset: GSM8K-------\n",
      "Already answered IDs: {0, 2, 3, 4, 6, 8, 18, 25, 27, 28, 29, 30, 33, 36, 38, 42, 44, 46, 49, 54, 62, 64, 65, 67, 72, 74, 79, 80, 82, 83, 85, 86, 89, 92, 93, 95, 100, 101, 102, 111, 117, 118, 125, 127, 128, 130, 132, 141, 143, 147, 151, 153, 159, 161, 164, 165, 166, 167, 168, 170, 183, 186, 187, 191, 194, 196, 200, 202, 205, 206, 207, 222, 223, 225, 226, 235, 236, 237, 239, 240, 243, 245, 253, 254, 255, 266, 267, 271, 273, 276, 283, 285, 286, 291, 296, 299, 300, 306, 309, 314, 315, 316, 322, 324, 327, 331, 336, 339, 343, 345, 346, 349, 351, 358, 365, 367, 369, 373, 376, 377, 378, 382, 384, 385, 386, 387, 389, 390, 391, 393, 394, 398, 403, 404, 406, 408, 412, 416, 418, 421, 424, 425, 431, 433, 436, 437, 440, 441, 447, 448, 451, 452, 454, 456, 459, 482, 485, 488, 489, 490, 491, 492, 495, 497, 499, 500, 509, 513, 525, 530, 531, 532, 533, 535, 555, 561, 562, 563, 564, 569, 570, 573, 574, 575, 577, 578, 589, 594, 596, 597, 598, 599, 616, 617, 619, 621, 635, 637, 639, 641, 644, 647, 649, 654, 655, 664, 666, 667, 676, 681, 682, 684, 686, 687, 691, 695, 701, 703, 710, 716, 717, 718, 721, 724, 731, 733, 734, 735, 746, 748, 751, 752, 758, 761, 762, 767, 769, 775, 788, 794, 795, 798, 801, 807, 812, 816, 817, 822, 823, 825, 827, 829, 831, 839, 841, 848, 850, 855, 856, 858, 861, 871, 872, 873, 877, 884, 889, 891, 893, 905, 906, 911, 912, 914, 915, 917, 922, 927, 930, 937, 939, 941, 956, 963, 965, 966, 974, 975, 976, 981, 986, 994, 995, 996, 997, 1002, 1005, 1006, 1008, 1010, 1012, 1024, 1028, 1031, 1033, 1038, 1039, 1040, 1041, 1042, 1045, 1046, 1047, 1067, 1068, 1073, 1074, 1076, 1077, 1080, 1081, 1084, 1090, 1094, 1103, 1106, 1107, 1109, 1111, 1112, 1114, 1118, 1120, 1121, 1123, 1128, 1129, 1131, 1138, 1139, 1143, 1145, 1153, 1156, 1162, 1163, 1166, 1168, 1174, 1175, 1176, 1178, 1179, 1180, 1181, 1187, 1191, 1192, 1194, 1199, 1202, 1203, 1207, 1209, 1221, 1224, 1225, 1227, 1230, 1231, 1232, 1235, 1240, 1241, 1243, 1247, 1249, 1251, 1252, 1253, 1259, 1261, 1266, 1271, 1273, 1276, 1279, 1287, 1290, 1291, 1294, 1295, 1296, 1297, 1300, 1310, 1315, 1317, 1318}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 320788.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: 788 Skipping: 861 Skipping: 82 Skipping: 530 Skipping: 1047 Skipping: 995 Skipping: 829 Skipping: 621 Skipping: 976 Skipping: 733 Skipping: 1194 Skipping: 447 Skipping: 1033 Skipping: 285 Skipping: 577 Skipping: 286 Skipping: 194 Skipping: 1266 Skipping: 513 Skipping: 1090 Skipping: 1232 Skipping: 300 Skipping: 635 Skipping: 202 Skipping: 151 Skipping: 676 Skipping: 966 Skipping: 206 Skipping: 724 Skipping: 889 Skipping: 647 Skipping: 1251 Skipping: 418 Skipping: 1131 Skipping: 1310 Skipping: 906 Skipping: 1067 Skipping: 533 Skipping: 127 Skipping: 1123 Skipping: 28 Skipping: 191 Skipping: 816 Skipping: 2 Skipping: 1253 Skipping: 1010 Skipping: 682 Skipping: 499 Skipping: 666 Skipping: 128 Skipping: 391 Skipping: 1162 Skipping: 454 Skipping: 488 Skipping: 291 Skipping: 1112 Skipping: 917 Skipping: 186 Skipping: 164 Skipping: 655 Skipping: 1040 Skipping: 1002 Skipping: 223 Skipping: 617 Skipping: 1128 Skipping: 596 Skipping: 255 Skipping: 1121 Skipping: 681 Skipping: 1106 Skipping: 416 Skipping: 1235 Skipping: 1120 Skipping: 1203 Skipping: 589 Skipping: 911 Skipping: 187 Skipping: 1221 Skipping: 1318 Skipping: 649 Skipping: 1178 Skipping: 495 Skipping: 594 Skipping: 376 Skipping: 387 Skipping: 382 Skipping: 67 Skipping: 532 Skipping: 975 Skipping: 141 Skipping: 183 Skipping: 266 Skipping: 306 Skipping: 79 Skipping: 1259 Skipping: 1107 Skipping: 801 Skipping: 1074 Skipping: 564 Skipping: 1068 Skipping: 482 Skipping: 440 Skipping: 1207 Skipping: 858 Skipping: 1187 Skipping: 563 Skipping: 922 Skipping: 1008 Skipping: 731 Skipping: 168 Skipping: 664 Skipping: 236 Skipping: 996 Skipping: 1202 Skipping: 686 Skipping: 389 Skipping: 497 Skipping: 33 Skipping: 555 Skipping: 239 Skipping: 451 Skipping: 761 Skipping: 349 Skipping: 1249 Skipping: 872 Skipping: 1279 Skipping: 1290 Skipping: 299 Skipping: 448 Skipping: 92 Skipping: 1175 Skipping: 1094 Skipping: 1294 Skipping: 54 Skipping: 254 Skipping: 386 Skipping: 1179 Skipping: 245 Skipping: 1240 Skipping: 1241 Skipping: 758 Skipping: 237 Skipping: 74 Skipping: 44 Skipping: 398 Skipping: 378 Skipping: 253 Skipping: 981 Skipping: 431 Skipping: 125 Skipping: 46 Skipping: 1114 Skipping: 871 Skipping: 207 Skipping: 1230 Skipping: 143 Skipping: 452 Skipping: 147 Skipping: 616 Skipping: 717 Skipping: 893 Skipping: 369 Skipping: 1168 Skipping: 1031 Skipping: 956 Skipping: 80 Skipping: 1191 Skipping: 1181 Skipping: 408 Skipping: 1163 Skipping: 734 Skipping: 963 Skipping: 346 Skipping: 1247 Skipping: 118 Skipping: 324 Skipping: 331 Skipping: 701 Skipping: 1084 Skipping: 1300 Skipping: 240 Skipping: 905 Skipping: 358 Skipping: 27 Skipping: 965 Skipping: 839 Skipping: 1041 Skipping: 637 Skipping: 1209 Skipping: 795 Skipping: 1138 Skipping: 314 Skipping: 25 Skipping: 937 Skipping: 161 Skipping: 687 Skipping: 93 Skipping: 1166 Skipping: 575 Skipping: 276 Skipping: 491 Skipping: 986 Skipping: 721 Skipping: 1243 Skipping: 735 Skipping: 271 Skipping: 1296 Skipping: 794 Skipping: 848 Skipping: 165 Skipping: 3 Skipping: 393 Skipping: 684 Skipping: 327 Skipping: 490 Skipping: 456 Skipping: 1261 Skipping: 775 Skipping: 1109 Skipping: 64 Skipping: 823 Skipping: 856 Skipping: 95 Skipping: 339 Skipping: 912 Skipping: 130 Skipping: 1315 Skipping: 322 Skipping: 914 Skipping: 1080 Skipping: 997 Skipping: 0 Skipping: 1224 Skipping: 1012 Skipping: 667 Skipping: 639 Skipping: 1153 Skipping: 102 Skipping: 850 Skipping: 385 Skipping: 170 Skipping: 267 Skipping: 30 Skipping: 822 Skipping: 855 Skipping: 1287 Skipping: 6 Skipping: 437 Skipping: 29 Skipping: 4 Skipping: 200 Skipping: 390 Skipping: 243 Skipping: 406 Skipping: 619 Skipping: 573 Skipping: 373 Skipping: 205 Skipping: 974 Skipping: 812 Skipping: 166 Skipping: 1174 Skipping: 562 Skipping: 927 Skipping: 1176 Skipping: 525 Skipping: 273 Skipping: 710 Skipping: 235 Skipping: 316 Skipping: 570 Skipping: 38 Skipping: 86 Skipping: 83 Skipping: 421 Skipping: 531 Skipping: 644 Skipping: 751 Skipping: 1045 Skipping: 1139 Skipping: 939 Skipping: 891 Skipping: 762 Skipping: 365 Skipping: 425 Skipping: 769 Skipping: 1252 Skipping: 18 Skipping: 283 Skipping: 309 Skipping: 1199 Skipping: 1271 Skipping: 691 Skipping: 752 Skipping: 1276 Skipping: 1145 Skipping: 798 Skipping: 1111 Skipping: 36 Skipping: 42 Skipping: 1118 Skipping: 167 Skipping: 153 Skipping: 1005 Skipping: 597 Skipping: 296 Skipping: 1156 Skipping: 404 Skipping: 561 Skipping: 132 Skipping: 1297 Skipping: 117 Skipping: 489 Skipping: 748 Skipping: 1180 Skipping: 1081 Skipping: 49 Skipping: 315 Skipping: 1227 Skipping: 877 Skipping: 535 Skipping: 746 Skipping: 72 Skipping: 1028 Skipping: 412 Skipping: 1073 Skipping: 336 Skipping: 1225 Skipping: 424 Skipping: 111 Skipping: 101 Skipping: 574 Skipping: 930 Skipping: 492 Skipping: 485 Skipping: 345 Skipping: 1317 Skipping: 817 Skipping: 831 Skipping: 351 Skipping: 1192 Skipping: 1103 Skipping: 1143 Skipping: 716 Skipping: 509 Skipping: 436 Skipping: 1046 Skipping: 994 Skipping: 343 Skipping: 1024 Skipping: 703 Skipping: 915 Skipping: 159 Skipping: 941 Skipping: 1077 Skipping: 641 Skipping: 578 Skipping: 384 Skipping: 825 Skipping: 654 Skipping: 89 Skipping: 1231 Skipping: 827 Skipping: 1039 Skipping: 1295 Skipping: 767 Skipping: 226 Skipping: 62 Skipping: 394 Skipping: 8 Skipping: 100 Skipping: 403 Skipping: 569 Skipping: 1042 Skipping: 1038 Skipping: 459 Skipping: 500 Skipping: 807 Skipping: 598 Skipping: 1129 Skipping: 695 Skipping: 222 Skipping: 433 Skipping: 85 Skipping: 377 Skipping: 225 Skipping: 1076 Skipping: 599 Skipping: 1273 Skipping: 1291 Skipping: 441 Skipping: 196 Skipping: 367 Skipping: 1006 Skipping: 65 Skipping: 841 Skipping: 884 Skipping: 873 Skipping: 718 Processing complete for GSM8K. 0 new answers saved to /Users/log/Github/textual_grounding/logan/results/final/VanillaCoT/GSM8K/llama3.170b/zero_shot_vanilla_cot_None_GSM8K_llama3.170b.csv.\n",
      "------Processing dataset: MultiArith-------\n",
      "Already answered IDs: {0, 1, 4, 6, 7, 8, 9, 11, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 25, 27, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 51, 52, 60, 61, 62, 63, 65, 66, 68, 69, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 111, 113, 114, 115, 116, 123, 124, 125, 126, 129, 130, 133, 134, 135, 140, 144, 145, 146, 147, 149, 151, 152, 155, 156, 160, 161, 162, 163, 165, 168, 172, 173, 174, 175, 177, 179, 181, 182, 184, 185, 188, 189, 190, 191, 193, 194, 195, 196, 198, 201, 203, 206, 207, 208, 210, 211, 212, 215, 216, 217, 218, 220, 221, 222, 223, 225, 226, 229, 230, 231, 232, 233, 234, 237, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 254, 255, 256, 258, 259, 260, 262, 263, 266, 268, 269, 271, 273, 274, 276, 277, 278, 281, 283, 284, 285, 289, 290, 291, 293, 294, 296, 297, 298, 300, 301, 303, 305, 307, 308, 310, 311, 312, 313, 315, 316, 317, 318, 319, 320, 321, 322, 325, 326, 327, 328, 329, 330, 331, 334, 335, 336, 337, 339, 340, 341, 342, 343, 344, 347, 349, 350, 351, 354, 355, 356, 357, 360, 361, 364, 365, 367, 369, 370, 371, 372, 374, 375, 377, 379, 380, 381, 384, 387, 389, 393, 395, 397, 398, 399, 401, 403, 404, 405, 406, 408, 409, 410, 411, 412, 413, 414, 415, 417, 419, 420, 421, 422, 424, 425, 427, 428, 429, 430, 432, 433, 435, 436, 438, 440, 441, 443, 447, 450, 451, 452, 453, 454, 456, 457, 458, 460, 461, 462, 463, 464, 467, 468, 470, 471, 472, 473, 474, 476, 478, 479, 480, 481, 482, 484, 485, 486, 487, 488, 490, 491, 492, 495, 496, 497, 498, 499, 500, 501, 503, 504, 505, 506, 507, 508, 509, 510, 511, 514, 517, 519, 520, 521, 523, 524, 525, 526, 527, 528, 530, 531, 534, 536, 537, 538, 540, 541, 542, 543, 545, 546, 548, 549, 550, 556, 558, 559, 560, 561, 562, 565, 566, 567, 569, 570, 571, 573, 575, 577, 578, 579, 580, 582, 583, 584, 585, 587, 588, 589, 591, 592, 594, 595, 597, 598, 599}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: 397 Skipping: 433 Skipping: 41 Skipping: 268 Skipping: 526 Skipping: 500 Skipping: 417 Skipping: 313 Skipping: 491 Skipping: 369 Skipping: 226 Skipping: 519 Skipping: 144 Skipping: 291 Skipping: 145 Skipping: 99 Skipping: 259 Skipping: 548 Skipping: 152 Skipping: 320 Skipping: 103 Skipping: 77 Skipping: 341 Skipping: 486 Skipping: 105 Skipping: 365 Skipping: 447 Skipping: 326 Skipping: 212 Skipping: 569 Skipping: 591 Skipping: 456 Skipping: 536 Skipping: 269 Skipping: 65 Skipping: 14 Skipping: 97 Skipping: 411 Skipping: 1 Skipping: 508 Skipping: 344 Skipping: 252 Skipping: 336 Skipping: 66 Skipping: 198 Skipping: 230 Skipping: 247 Skipping: 147 Skipping: 461 Skipping: 95 Skipping: 84 Skipping: 330 Skipping: 523 Skipping: 504 Skipping: 113 Skipping: 311 Skipping: 301 Skipping: 129 Skipping: 343 Skipping: 211 Skipping: 297 Skipping: 458 Skipping: 549 Skipping: 599 Skipping: 327 Skipping: 250 Skipping: 300 Skipping: 190 Skipping: 196 Skipping: 194 Skipping: 33 Skipping: 566 Skipping: 490 Skipping: 72 Skipping: 93 Skipping: 135 Skipping: 155 Skipping: 39 Skipping: 582 Skipping: 403 Skipping: 285 Skipping: 244 Skipping: 223 Skipping: 432 Skipping: 284 Skipping: 233 Skipping: 255 Skipping: 577 Skipping: 331 Skipping: 361 Skipping: 472 Skipping: 506 Skipping: 409 Skipping: 184 Skipping: 42 Skipping: 168 Skipping: 316 Skipping: 61 Skipping: 558 Skipping: 303 Skipping: 325 Skipping: 173 Skipping: 435 Skipping: 584 Skipping: 126 Skipping: 8 Skipping: 377 Skipping: 140 Skipping: 501 Skipping: 364 Skipping: 114 Skipping: 193 Skipping: 507 Skipping: 89 Skipping: 172 Skipping: 221 Skipping: 420 Skipping: 31 Skipping: 52 Skipping: 588 Skipping: 76 Skipping: 440 Skipping: 360 Skipping: 488 Skipping: 23 Skipping: 421 Skipping: 296 Skipping: 534 Skipping: 468 Skipping: 276 Skipping: 543 Skipping: 351 Skipping: 37 Skipping: 13 Skipping: 565 Skipping: 328 Skipping: 98 Skipping: 592 Skipping: 428 Skipping: 538 Skipping: 63 Skipping: 203 Skipping: 47 Skipping: 191 Skipping: 429 Skipping: 595 Skipping: 18 Skipping: 550 Skipping: 11 Skipping: 101 Skipping: 96 Skipping: 370 Skipping: 464 Skipping: 248 Skipping: 109 Skipping: 375 Skipping: 412 Skipping: 481 Skipping: 350 Skipping: 450 Skipping: 281 Skipping: 220 Skipping: 580 Skipping: 480 Skipping: 430 Skipping: 546 Skipping: 35 Skipping: 115 Skipping: 36 Skipping: 334 Skipping: 156 Skipping: 181 Skipping: 589 Skipping: 94 Skipping: 441 Skipping: 260 Skipping: 242 Skipping: 20 Skipping: 308 Skipping: 496 Skipping: 509 Skipping: 457 Skipping: 104 Skipping: 598 Skipping: 185 Skipping: 492 Skipping: 243 Skipping: 294 Skipping: 88 Skipping: 476 Skipping: 347 Skipping: 106 Skipping: 395 Skipping: 29 Skipping: 349 Skipping: 83 Skipping: 520 Skipping: 177 Skipping: 274 Skipping: 130 Skipping: 62 Skipping: 482 Skipping: 229 Skipping: 540 Skipping: 91 Skipping: 6 Skipping: 517 Skipping: 467 Skipping: 571 Skipping: 562 Skipping: 263 Skipping: 161 Skipping: 335 Skipping: 505 Skipping: 201 Skipping: 339 Skipping: 399 Skipping: 80 Skipping: 290 Skipping: 356 Skipping: 393 Skipping: 237 Skipping: 40 Skipping: 497 Skipping: 474 Skipping: 438 Skipping: 585 Skipping: 71 Skipping: 124 Skipping: 249 Skipping: 182 Skipping: 315 Skipping: 149 Skipping: 408 Skipping: 414 Skipping: 305 Skipping: 471 Skipping: 436 Skipping: 69 Skipping: 160 Skipping: 384 Skipping: 215 Skipping: 556 Skipping: 597 Skipping: 0 Skipping: 307 Skipping: 100 Skipping: 443 Skipping: 479 Skipping: 573 Skipping: 116 Skipping: 329 Skipping: 232 Skipping: 530 Skipping: 293 Skipping: 357 Skipping: 16 Skipping: 208 Skipping: 559 Skipping: 217 Skipping: 374 Skipping: 86 Skipping: 231 Skipping: 32 Skipping: 134 Skipping: 82 Skipping: 379 Skipping: 273 Skipping: 594 Skipping: 380 Skipping: 312 Skipping: 354 Skipping: 19 Skipping: 256 Skipping: 503 Skipping: 387 Skipping: 422 Skipping: 25 Skipping: 406 Skipping: 462 Skipping: 283 Skipping: 545 Skipping: 68 Skipping: 7 Skipping: 511 Skipping: 216 Skipping: 163 Skipping: 561 Skipping: 111 Skipping: 367 Skipping: 470 Skipping: 510 Skipping: 51 Skipping: 495 Skipping: 398 Skipping: 579 Skipping: 460 Skipping: 372 Skipping: 567 Skipping: 419 Skipping: 246 Skipping: 206 Skipping: 355 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 55.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: 234 Skipping: 453 Skipping: 133 Skipping: 70 Skipping: 527 Skipping: 179 Skipping: 60 Skipping: 81 Skipping: 587 Skipping: 9 Skipping: 21 Skipping: 473 Skipping: 107 Skipping: 454 Skipping: 463 Skipping: 189 Skipping: 318 Skipping: 498 Skipping: 413 Skipping: 225 Skipping: 487 Skipping: 524 Skipping: 108 Skipping: 195 Skipping: 151 Skipping: 4 Skipping: 525 Skipping: 79 Skipping: 570 Skipping: 484 Skipping: 174 Skipping: 531 Skipping: 48 Skipping: 175 Skipping: 452 Skipping: 277 Skipping: 371 Skipping: 560 Skipping: 38 Skipping: 254 Skipping: 289 Skipping: 478 Skipping: 425 Skipping: 499 Skipping: 389 Skipping: 528 Skipping: 578 Skipping: 405 Skipping: 404 Skipping: 278 Skipping: 537 Skipping: 322 Skipping: 12 Skipping: 381 Skipping: 46 Skipping: 222 Skipping: 415 Skipping: 188 Skipping: 583 Skipping: 266 Skipping: 575 Skipping: 451 Skipping: 337 Skipping: 78 Skipping: 271 Skipping: 27 Skipping: 321 Skipping: 542 Skipping: 125 Skipping: 123 Skipping: 410 Skipping: 218 Skipping: 207 Skipping: 210 Skipping: 485 Skipping: 424 Skipping: 245 Skipping: 298 Skipping: 427 Skipping: 541 Skipping: 310 Skipping: 514 Skipping: 340 Skipping: 87 Skipping: 262 Skipping: 401 Skipping: 521 Skipping: 317 Skipping: 162 Skipping: 146 Skipping: 319 Skipping: 165 Skipping: 22 Skipping: 342 Skipping: 258 Processing complete for MultiArith. 2 new answers saved to /Users/log/Github/textual_grounding/logan/results/final/VanillaCoT/MultiArith/llama3.170b/zero_shot_vanilla_cot_None_MultiArith_llama3.170b.csv.\n",
      "------Processing dataset: ASDiv-------\n",
      "Already answered IDs: {0, 2049, 3, 4, 2053, 6, 2058, 2063, 2071, 25, 27, 30, 31, 34, 2085, 39, 2092, 45, 47, 2096, 2098, 2099, 55, 2103, 58, 2108, 2111, 65, 68, 2120, 2123, 76, 2125, 2127, 81, 82, 85, 88, 2141, 94, 95, 2144, 97, 2147, 2151, 104, 2153, 2160, 2161, 2163, 120, 127, 2176, 129, 132, 2181, 2190, 143, 145, 149, 2198, 2199, 2200, 153, 2201, 2206, 2210, 2212, 164, 2217, 169, 171, 2220, 173, 2223, 177, 179, 2229, 2235, 2236, 2238, 2244, 2248, 203, 207, 2259, 2266, 220, 2270, 2272, 225, 2274, 2275, 226, 227, 2284, 2287, 2293, 2294, 2302, 255, 256, 257, 259, 260, 263, 265, 273, 274, 275, 277, 286, 287, 291, 293, 296, 319, 322, 326, 334, 336, 342, 344, 347, 349, 351, 359, 366, 369, 378, 389, 393, 396, 398, 402, 405, 406, 407, 408, 409, 410, 413, 418, 424, 426, 428, 432, 436, 451, 457, 460, 466, 468, 471, 472, 476, 502, 510, 511, 515, 517, 533, 545, 550, 552, 576, 583, 584, 585, 591, 593, 594, 596, 606, 614, 619, 621, 626, 644, 645, 647, 666, 668, 670, 678, 681, 697, 700, 714, 717, 719, 720, 734, 743, 750, 754, 764, 767, 768, 791, 794, 808, 815, 821, 835, 836, 865, 877, 887, 888, 902, 904, 913, 915, 920, 921, 923, 936, 937, 958, 959, 970, 973, 976, 977, 979, 982, 987, 992, 1002, 1021, 1028, 1030, 1039, 1040, 1042, 1064, 1069, 1079, 1080, 1082, 1092, 1099, 1118, 1123, 1135, 1180, 1186, 1188, 1194, 1200, 1202, 1204, 1214, 1226, 1227, 1234, 1240, 1241, 1243, 1248, 1268, 1269, 1274, 1282, 1283, 1285, 1286, 1295, 1298, 1299, 1307, 1331, 1333, 1337, 1338, 1347, 1356, 1357, 1368, 1370, 1371, 1375, 1376, 1377, 1380, 1384, 1388, 1389, 1407, 1408, 1422, 1427, 1432, 1433, 1434, 1435, 1437, 1446, 1457, 1460, 1468, 1472, 1477, 1480, 1486, 1493, 1496, 1502, 1507, 1517, 1520, 1534, 1536, 1540, 1541, 1546, 1547, 1548, 1550, 1552, 1556, 1567, 1571, 1585, 1587, 1589, 1591, 1593, 1594, 1601, 1604, 1606, 1609, 1611, 1622, 1623, 1626, 1627, 1642, 1646, 1661, 1682, 1690, 1729, 1742, 1744, 1748, 1757, 1768, 1774, 1778, 1800, 1812, 1819, 1821, 1824, 1830, 1831, 1834, 1835, 1836, 1853, 1855, 1859, 1860, 1865, 1867, 1870, 1879, 1881, 1887, 1894, 1895, 1897, 1904, 1908, 1912, 1913, 1919, 1922, 1927, 1928, 1936, 1945, 1948, 1953, 1957, 1975, 1997, 2001, 2009, 2011, 2019, 2022, 2039, 2040, 2044, 2045, 2047}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 480722.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: 1774 Skipping: 1919 Skipping: 171 Skipping: 1180 Skipping: 2198 Skipping: 1855 Skipping: 1377 Skipping: 2160 Skipping: 1623 Skipping: 959 Skipping: 2275 Skipping: 591 Skipping: 1274 Skipping: 593 Skipping: 408 Skipping: 1118 Skipping: 626 Skipping: 1407 Skipping: 424 Skipping: 322 Skipping: 1502 Skipping: 2141 Skipping: 432 Skipping: 1606 Skipping: 1975 Skipping: 1432 Skipping: 902 Skipping: 2161 Skipping: 2019 Skipping: 1186 Skipping: 275 Skipping: 58 Skipping: 402 Skipping: 1830 Skipping: 4 Skipping: 2229 Skipping: 1520 Skipping: 1082 Skipping: 1480 Skipping: 277 Skipping: 815 Skipping: 973 Skipping: 1042 Skipping: 606 Skipping: 2040 Skipping: 393 Skipping: 349 Skipping: 1457 Skipping: 2212 Skipping: 466 Skipping: 645 Skipping: 1248 Skipping: 621 Skipping: 1604 Skipping: 2274 Skipping: 1241 Skipping: 714 Skipping: 1865 Skipping: 2096 Skipping: 1226 Skipping: 436 Skipping: 2181 Skipping: 1834 Skipping: 1370 Skipping: 1240 Skipping: 1333 Skipping: 614 Skipping: 976 Skipping: 207 Skipping: 1356 Skipping: 1831 Skipping: 821 Skipping: 681 Skipping: 1298 Skipping: 515 Skipping: 619 Skipping: 396 Skipping: 407 Skipping: 1879 Skipping: 2272 Skipping: 68 Skipping: 1389 Skipping: 2217 Skipping: 1493 Skipping: 552 Skipping: 1040 Skipping: 143 Skipping: 203 Skipping: 1547 Skipping: 1748 Skipping: 286 Skipping: 2001 Skipping: 326 Skipping: 2099 Skipping: 81 Skipping: 1922 Skipping: 169 Skipping: 2045 Skipping: 1589 Skipping: 2098 Skipping: 1895 Skipping: 1227 Skipping: 1556 Skipping: 865 Skipping: 1912 Skipping: 1601 Skipping: 1194 Skipping: 585 Skipping: 1188 Skipping: 1859 Skipping: 502 Skipping: 1936 Skipping: 460 Skipping: 2039 Skipping: 1548 Skipping: 1337 Skipping: 1887 Skipping: 2153 Skipping: 923 Skipping: 1307 Skipping: 584 Skipping: 987 Skipping: 1092 Skipping: 2284 Skipping: 1460 Skipping: 1591 Skipping: 2085 Skipping: 1821 Skipping: 764 Skipping: 177 Skipping: 697 Skipping: 2223 Skipping: 256 Skipping: 1079 Skipping: 1331 Skipping: 1427 Skipping: 719 Skipping: 1927 Skipping: 409 Skipping: 517 Skipping: 34 Skipping: 1661 Skipping: 576 Skipping: 259 Skipping: 2199 Skipping: 471 Skipping: 794 Skipping: 1824 Skipping: 369 Skipping: 2248 Skipping: 937 Skipping: 1867 Skipping: 129 Skipping: 226 Skipping: 1800 Skipping: 319 Skipping: 1948 Skipping: 1585 Skipping: 468 Skipping: 94 Skipping: 1870 Skipping: 1295 Skipping: 1435 Skipping: 2071 Skipping: 2125 Skipping: 1214 Skipping: 1368 Skipping: 1550 Skipping: 153 Skipping: 55 Skipping: 274 Skipping: 1437 Skipping: 406 Skipping: 1376 Skipping: 1897 Skipping: 1299 Skipping: 265 Skipping: 2201 Skipping: 2236 Skipping: 791 Skipping: 1904 Skipping: 257 Skipping: 76 Skipping: 1375 Skipping: 45 Skipping: 418 Skipping: 398 Skipping: 1627 Skipping: 273 Skipping: 1064 Skipping: 451 Skipping: 1646 Skipping: 1836 Skipping: 127 Skipping: 2190 Skipping: 47 Skipping: 1234 Skipping: 936 Skipping: 2287 Skipping: 227 Skipping: 1908 Skipping: 2220 Skipping: 145 Skipping: 472 Skipping: 149 Skipping: 1472 Skipping: 644 Skipping: 750 Skipping: 958 Skipping: 389 Skipping: 2111 Skipping: 1123 Skipping: 1021 Skipping: 82 Skipping: 2235 Skipping: 2151 Skipping: 2206 Skipping: 2127 Skipping: 428 Skipping: 2103 Skipping: 767 Skipping: 2058 Skipping: 2163 Skipping: 1028 Skipping: 1913 Skipping: 2053 Skipping: 1286 Skipping: 366 Skipping: 2147 Skipping: 1534 Skipping: 2244 Skipping: 1768 Skipping: 120 Skipping: 1812 Skipping: 1541 Skipping: 344 Skipping: 1928 Skipping: 351 Skipping: 734 Skipping: 1204 Skipping: 533 Skipping: 260 Skipping: 1357 Skipping: 970 Skipping: 1517 Skipping: 378 Skipping: 27 Skipping: 1030 Skipping: 1552 Skipping: 904 Skipping: 2049 Skipping: 1285 Skipping: 1997 Skipping: 1135 Skipping: 668 Skipping: 1477 Skipping: 2176 Skipping: 836 Skipping: 2200 Skipping: 1496 Skipping: 2063 Skipping: 334 Skipping: 1268 Skipping: 1571 Skipping: 25 Skipping: 1002 Skipping: 1690 Skipping: 164 Skipping: 720 Skipping: 1682 Skipping: 95 Skipping: 2108 Skipping: 596 Skipping: 296 Skipping: 511 Skipping: 1757 Skipping: 1069 Skipping: 754 Skipping: 1384 Skipping: 2238 Skipping: 1536 Skipping: 768 Skipping: 1338 Skipping: 1434 Skipping: 1945 Skipping: 1408 Skipping: 291 Skipping: 1622 Skipping: 666 Skipping: 835 Skipping: 1729 Skipping: 913 Skipping: 1894 Skipping: 2266 Skipping: 2302 Skipping: 3 Skipping: 1347 Skipping: 413 Skipping: 1587 Skipping: 717 Skipping: 347 Skipping: 510 Skipping: 476 Skipping: 1446 Skipping: 982 Skipping: 808 Skipping: 1611 Skipping: 2022 Skipping: 1283 Skipping: 2011 Skipping: 65 Skipping: 888 Skipping: 1594 Skipping: 1282 Skipping: 921 Skipping: 1778 Skipping: 1507 Skipping: 1609 Skipping: 97 Skipping: 359 Skipping: 977 Skipping: 132 Skipping: 550 Skipping: 1593 Skipping: 342 Skipping: 979 Skipping: 1200 Skipping: 1080 Skipping: 1269 Skipping: 1371 Skipping: 1744 Skipping: 0 Skipping: 2210 Skipping: 1099 Skipping: 700 Skipping: 670 Skipping: 2044 Skipping: 2092 Skipping: 104 Skipping: 1853 Skipping: 1881 Skipping: 1860 Skipping: 915 Skipping: 405 Skipping: 1243 Skipping: 1433 Skipping: 179 Skipping: 1957 Skipping: 1642 Skipping: 287 Skipping: 31 Skipping: 887 Skipping: 1546 Skipping: 920 Skipping: 678 Skipping: 6 Skipping: 457 Skipping: 30 Skipping: 1626 Skipping: 1742 Skipping: 2270 Skipping: 1953 Skipping: 1540 Skipping: 1202 Skipping: 1388 Skipping: 220 Skipping: 410 Skipping: 263 Skipping: 1380 Skipping: 2047 Skipping: 426 Skipping: 647 Skipping: 594 Skipping: 1567 Skipping: 2259 Skipping: 225 Skipping: 1039 Skipping: 877 Skipping: 1422 Skipping: 173 Skipping: 2120 Skipping: 583 Skipping: 992 Skipping: 1835 Skipping: 1819 Skipping: 2123 Skipping: 545 Skipping: 293 Skipping: 1486 Skipping: 2294 Skipping: 2144 Skipping: 2009 Skipping: 1468 Skipping: 743 Skipping: 255 Skipping: 336 Skipping: 2293 Skipping: 39 Skipping: 88 Skipping: 85 Processing complete for ASDiv. 0 new answers saved to /Users/log/Github/textual_grounding/logan/results/final/VanillaCoT/ASDiv/llama3.170b/zero_shot_vanilla_cot_None_ASDiv_llama3.170b.csv.\n",
      "------Processing dataset: SVAMP-------\n",
      "Already answered IDs: {1, 516, 520, 523, 14, 16, 533, 534, 537, 545, 33, 39, 41, 553, 556, 560, 561, 564, 565, 573, 63, 64, 581, 70, 75, 589, 593, 82, 84, 597, 601, 91, 603, 93, 95, 97, 610, 101, 103, 616, 617, 111, 625, 626, 627, 118, 119, 633, 122, 127, 640, 133, 645, 142, 143, 655, 145, 656, 149, 150, 153, 672, 676, 684, 174, 695, 699, 700, 188, 191, 193, 194, 195, 716, 717, 720, 209, 722, 723, 208, 727, 220, 223, 736, 225, 227, 747, 749, 241, 244, 247, 248, 249, 256, 773, 775, 776, 265, 266, 277, 281, 282, 288, 802, 803, 294, 297, 298, 812, 813, 817, 818, 308, 310, 822, 824, 829, 317, 831, 834, 323, 324, 327, 841, 844, 333, 332, 847, 849, 338, 851, 340, 341, 852, 343, 860, 862, 864, 868, 870, 362, 876, 365, 366, 881, 884, 886, 888, 889, 891, 892, 380, 379, 896, 903, 904, 394, 909, 911, 400, 913, 915, 920, 408, 923, 414, 929, 931, 934, 938, 939, 940, 429, 430, 436, 952, 444, 960, 453, 966, 455, 967, 458, 971, 461, 984, 986, 988, 483, 998, 487, 488, 497, 498, 501, 504, 505}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: 864 Skipping: 394 Skipping: 776 Skipping: 911 Skipping: 430 Skipping: 41 Skipping: 265 Skipping: 988 Skipping: 523 Skipping: 497 Skipping: 414 Skipping: 940 Skipping: 802 Skipping: 849 Skipping: 310 Skipping: 488 Skipping: 366 Skipping: 597 Skipping: 913 Skipping: 929 Skipping: 223 Skipping: 516 Skipping: 142 Skipping: 288 Skipping: 143 Skipping: 773 Skipping: 97 Skipping: 633 Skipping: 818 Skipping: 256 Skipping: 931 Skipping: 545 Skipping: 722 Skipping: 829 Skipping: 616 Skipping: 923 Skipping: 150 Skipping: 317 Skipping: 101 Skipping: 747 Skipping: 75 Skipping: 920 Skipping: 870 Skipping: 700 Skipping: 338 Skipping: 483 Skipping: 573 Skipping: 103 Skipping: 362 Skipping: 444 Skipping: 323 Skipping: 625 Skipping: 655 Skipping: 934 Skipping: 209 Skipping: 565 Skipping: 984 Skipping: 453 Skipping: 886 Skipping: 533 Skipping: 266 Skipping: 63 Skipping: 824 Skipping: 561 Skipping: 14 Skipping: 95 Skipping: 736 Skipping: 860 Skipping: 408 Skipping: 727 Skipping: 844 Skipping: 803 Skipping: 684 Skipping: 640 Skipping: 1 Skipping: 626 Skipping: 505 Skipping: 847 Skipping: 888 Skipping: 341 Skipping: 249 Skipping: 960 Skipping: 333 Skipping: 720 Skipping: 891 Skipping: 64 Skipping: 195 Skipping: 581 Skipping: 227 Skipping: 244 Skipping: 822 Skipping: 145 Skipping: 909 Skipping: 556 Skipping: 458 Skipping: 93 Skipping: 82 Skipping: 327 Skipping: 896 Skipping: 520 Skipping: 501 Skipping: 111 Skipping: 308 Skipping: 564 Skipping: 298 Skipping: 723 Skipping: 127 Skipping: 560 Skipping: 340 Skipping: 834 Skipping: 553 Skipping: 208 Skipping: 971 Skipping: 617 Skipping: 892 Skipping: 601 Skipping: 294 Skipping: 455 Skipping: 904 Skipping: 610 Skipping: 817 Skipping: 998 Skipping: 324 Skipping: 589 Skipping: 247 Skipping: 297 Skipping: 188 Skipping: 193 Skipping: 841 Skipping: 191 Skipping: 33 Skipping: 627 Skipping: 672 Skipping: 939 Skipping: 487 Skipping: 70 Skipping: 91 Skipping: 695 Skipping: 775 Skipping: 133 Skipping: 153 Skipping: 39 Skipping: 903 Skipping: 716 Skipping: 986 Skipping: 889 Skipping: 699 Skipping: 400 Skipping: 967 Skipping: 537 Skipping: 282 Skipping: 534 Skipping: 831 Skipping: 241 Skipping: 220 Skipping: 862 Skipping: 603 Skipping: 429 Skipping: 593 Skipping: 281 Skipping: 461 Skipping: 504 Skipping: 676 Skipping: 656 Skipping: 717 Skipping: 812 Skipping: 365 Skipping: 84 Skipping: 332 Skipping: 868 Skipping: 118 Skipping: 498 Skipping: 884 Skipping: 645 Skipping: 343 Skipping: 194 Skipping: 248 Skipping: 16 Skipping: 749 Skipping: 277 Skipping: 119 Skipping: 851 Skipping: 225 Skipping: 380 Skipping: 813 Skipping: 174 Skipping: 915 Skipping: 436 Skipping: 938 Skipping: 952 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 191/400 [00:04<00:05, 40.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: 149 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 206/400 [01:15<05:47,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: 876 Skipping: 122 Skipping: 852 Skipping: 881 Skipping: 379 Skipping: 966 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [14:23<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete for SVAMP. 203 new answers saved to /Users/log/Github/textual_grounding/logan/results/final/VanillaCoT/SVAMP/llama3.170b/zero_shot_vanilla_cot_None_SVAMP_llama3.170b.csv.\n",
      "------Processing dataset: AQUA-------\n",
      "Initialized new save file with headers at: /Users/log/Github/textual_grounding/logan/results/final/VanillaCoT/AQUA/llama3.170b/zero_shot_vanilla_cot_None_AQUA_llama3.170b.csv\n",
      "Already answered IDs: set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 179/254 [14:24<06:02,  4.83s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m few_shot_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      5\u001b[0m sample_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m\n\u001b[0;32m----> 7\u001b[0m run_model(llm_model, prompt_type, few_shot_txt, sample_size, project_root)\n",
      "Cell \u001b[0;32mIn[99], line 27\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(llm_model, prompt_type, few_shot_txt, sample_size, project_root)\u001b[0m\n\u001b[1;32m     24\u001b[0m initialize_save_file(save_path)\n\u001b[1;32m     25\u001b[0m already_answered_ids \u001b[38;5;241m=\u001b[39m load_already_answered_ids(save_path)\n\u001b[0;32m---> 27\u001b[0m ids_answered, questions_answered, answers \u001b[38;5;241m=\u001b[39m query_llm(\n\u001b[1;32m     28\u001b[0m     llm_model\u001b[38;5;241m=\u001b[39mllm_model,\n\u001b[1;32m     29\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m     30\u001b[0m     questions\u001b[38;5;241m=\u001b[39mquestions,\n\u001b[1;32m     31\u001b[0m     few_shot_prompt\u001b[38;5;241m=\u001b[39mfew_shot_prompt,\n\u001b[1;32m     32\u001b[0m     prompt_type\u001b[38;5;241m=\u001b[39mprompt_type,\n\u001b[1;32m     33\u001b[0m     save_path\u001b[38;5;241m=\u001b[39msave_path,\n\u001b[1;32m     34\u001b[0m     already_answered_ids\u001b[38;5;241m=\u001b[39malready_answered_ids\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing complete for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids_answered)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m new answers saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[97], line 34\u001b[0m, in \u001b[0;36mquery_llm\u001b[0;34m(llm_model, ids, questions, few_shot_prompt, prompt_type, save_path, already_answered_ids)\u001b[0m\n\u001b[1;32m     32\u001b[0m     answer \u001b[38;5;241m=\u001b[39m query_llama(prompt)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m llm_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama3.170b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     answer \u001b[38;5;241m=\u001b[39m query_llama_70b(prompt)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported LLM model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllm_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[83], line 54\u001b[0m, in \u001b[0;36mquery_llama_70b\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     38\u001b[0m client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI(\n\u001b[1;32m     39\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMBANOVA_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     40\u001b[0m     base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.sambanova.ai/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     44\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMeta-Llama-3.1-70B-Instruct\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     45\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     top_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m \u001b[38;5;66;03m# Meta default\u001b[39;00m\n\u001b[1;32m     53\u001b[0m )\n\u001b[0;32m---> 54\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Pause execution for 2 seconds\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "llm_model = 'llama3.170b'\n",
    "project_root = '/Users/log/Github/textual_grounding/'\n",
    "prompt_type = 'zero_shot_vanilla_cot'\n",
    "few_shot_txt = None\n",
    "sample_size = 400\n",
    "\n",
    "run_model(llm_model, prompt_type, few_shot_txt, sample_size, project_root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
