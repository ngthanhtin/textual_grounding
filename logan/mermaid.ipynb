{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ollama\n",
    "import google.generativeai as genai\n",
    "import anthropic\n",
    "import ollama\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from google.generativeai.types import RequestOptions\n",
    "from google.api_core import retry\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "import visualize\n",
    "import pandas as pd\n",
    "from utils.utils import add_color_to_tags, extract_parts_0, extract_parts_1\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(save_path: str, ids: List[str], questions: List[str], answers: List[str], append: bool = False):\n",
    "    \"\"\"\n",
    "    Saves the results to a CSV file. If append is True and the file exists, it appends without headers.\n",
    "    Otherwise, it writes a new file with headers.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'id': ids, 'question': questions, 'answer': answers})\n",
    "    if append and os.path.exists(save_path):\n",
    "        df.to_csv(save_path, mode='a', index=False, header=False)\n",
    "    else:\n",
    "        df.to_csv(save_path, index=False)\n",
    "\n",
    "def read_jsonl_file(filepath: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Reads a JSONL file and returns a list of JSON objects.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line)\n",
    "            data.append(json_obj)\n",
    "    return data\n",
    "\n",
    "def get_prompt(prompt_type: str, few_shot_prompt: str, question: str) -> str:\n",
    "    \"\"\"\n",
    "    Constructs the prompt based on the prompt type.\n",
    "    \"\"\"\n",
    "    prompts = {\n",
    "        \"cot\": f\"{few_shot_prompt}\\n{question}\\nPlease generate your explanation first, then generate the answer in the bracket as follow:\\n\" +\"Answer: {}\",\n",
    "        \"fs\": f\"{few_shot_prompt}\\n{question}\",\n",
    "        \"fs_inst\": f\"{few_shot_prompt}\\n{question}\\nI want you to answer this question but your explanation should contain references referring back to the information in the question. To do that, first, re-generate the question with proper tags and then generate your answers. The output format is as follow:\\n\\\n",
    "            Reformatted Question: \\\n",
    "                Answer:\",\n",
    "        \"zs\": f\"{question}\\nI want you to answer this question but your explanation should contain references referring back to the information in the question. To do that, first, re-generate the question with proper tags (<a>, <b>, <c>, etc) for refered information and then generate your answers that also have the tag (<a>, <b>, <c>, etc) for the grounded information. Give your answer by analyzing step by step, and give only numbers in the final answer. The output format is as follow:\\n\\\n",
    "            Reformatted Question: \\\n",
    "                Answer:\\\n",
    "                    Final answer:\",\n",
    "        \"fs_xml\": f\"{few_shot_prompt}\\n\\nRecreate the following question in the style of the correctly formatted examples shown previously. Make sure that your response has all its information inclosed in the proper <tags>. Begin your response with the <key_facts> section. Make sure that every fact in <key_facts> is very concise and contains a very short reference to the <question>. Do not include a <question> section in your response\\n\\n<question>\\n{question}\\n</question>\",\n",
    "        \"mermaid_get_answer\": f\"{few_shot_prompt}\\n\\n Your job is to extract the key facts from a question relevant to answering the question. The facts should be represented in a hierarchal format through a mermaid diagram. Do not create duplicate facts across multiple branches that represent the same information. Create a mermaid diagram that represents the key facts in the following question. Then, use the nodes from this graph to cite specific facts in your answer reasoning. Put your final answer in curly brackets e.g. Final_Answer: {{30}} \\n\\nquestion: {question}\", \n",
    "    }\n",
    "    return prompts.get(prompt_type, \"\")\n",
    "\n",
    "# cycle through all the keys \n",
    "def get_gemini_key(problem_id):\n",
    "    GOOGLE_KEYS = [\n",
    "        # 'AIzaSyBQ7zvIZoET3199GNhuz86vKagn_JCEOmk', # original - gen lang client\n",
    "        'AIzaSyCEI-5U4z7-3q-uwlvkOrdT2e78aNmjnbg', # chat app\n",
    "        # 'AIzaSyCvycd0yZZ4GSj47qDLk4JoPemvzUSfvio', # project 1\n",
    "        'AIzaSyD5xNbDkaJMEMBpWEXYNq5SheF6omdKpzg', # project 2\n",
    "        'AIzaSyAjcrp_otRjGsj0YvB1cUc2BMng6KSEZwU', # project 3\n",
    "    ]\n",
    "    index = problem_id%len(GOOGLE_KEYS)\n",
    "    print(f\"getting key from {index}\")\n",
    "    key = GOOGLE_KEYS[index]\n",
    "    return key\n",
    "\n",
    "def query_gemini(prompt: str, problem_id) -> str:\n",
    "    \"\"\"\n",
    "    Queries the Gemini LLM with the given prompt and returns the response text.\n",
    "    \"\"\"\n",
    "    genai.configure(api_key=get_gemini_key(problem_id))\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "    response = model.generate_content(prompt, request_options=RequestOptions(retry=retry.Retry(initial=20, multiplier=3, maximum=121, timeout=60)))\n",
    "    text = response.candidates[0].content.parts[0].text\n",
    "    return text\n",
    "\n",
    "def query_claude(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Queries the Claude LLM with the given prompt and returns the response text.\n",
    "    \"\"\"\n",
    "    client = anthropic.Anthropic(api_key=API_KEYS['claude'])\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=1024,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.content[0].text\n",
    "\n",
    "def query_llm(llm_model: str, ids: List[str], questions: List[str], few_shot_prompt: str, prompt_type: str, save_path: str, already_answered_ids: set) -> Tuple[List[str], List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Queries the specified LLM for each question, skipping already answered ones.\n",
    "    Saves each response immediately after it's obtained.\n",
    "    Returns lists of answered IDs, questions, and answers.\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "    ids_can_be_answered = []\n",
    "    questions_can_be_answered = []\n",
    "    \n",
    "    for id, q in tqdm(zip(ids, questions), total=len(ids)):\n",
    "        # print(f\"Processing ID: {id}\")\n",
    "        if id in already_answered_ids:\n",
    "            print(f\"Skipping already answered ID: {id}\")\n",
    "            continue\n",
    "        \n",
    "        prompt = get_prompt(prompt_type, few_shot_prompt, q)\n",
    "        try:\n",
    "            if llm_model == 'gemini':\n",
    "                answer = query_gemini(prompt, id)\n",
    "            elif llm_model == 'claude':\n",
    "                answer = query_claude(prompt)\n",
    "            elif llm_model == 'llama3.1':\n",
    "                answer = ollama.generate(model='llama3.1', prompt=prompt)['response']\n",
    "                print(f\"Processed ID: {id}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported LLM model: {llm_model}\")\n",
    "            # print(f\"Answer for ID {id}: {answer}\")\n",
    "            \n",
    "            # Append to lists\n",
    "            answers.append(answer)\n",
    "            questions_can_be_answered.append(q)\n",
    "            ids_can_be_answered.append(id)\n",
    "\n",
    "            # Save after each answer\n",
    "            save_results(save_path, [id], [q], [answer], append=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {id}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return ids_can_be_answered, questions_can_be_answered, answers\n",
    "\n",
    "def load_data(data_path: str, sample_size: int = None) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Loads data from a JSONL file, optionally sampling a subset.\n",
    "    \"\"\"\n",
    "    data = read_jsonl_file(data_path)\n",
    "    print(f\"Loaded {len(data)} records from: {data_path}\")\n",
    "    if sample_size:\n",
    "        data = random.sample(data, sample_size)\n",
    "        print(f\"Sampled {sample_size} records.\")\n",
    "    questions = [x[\"question\"] for x in data]\n",
    "    ids = [x[\"id\"] for x in data]\n",
    "    return ids, questions\n",
    "\n",
    "def load_data_deterministic(data_path: str, sample_size: int = None) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Loads data from a JSONL file in a deterministic manner by sorting.\n",
    "    \"\"\"\n",
    "    data = read_jsonl_file(data_path)\n",
    "    print(f\"Loaded {len(data)} records from: {data_path}\")\n",
    "    if sample_size:\n",
    "        # Sort the data based on a consistent criterion (e.g., 'id' or 'question')\n",
    "        sorted_data = sorted(data, key=lambda x: x['id'])\n",
    "        # Take the first 'sample_size' items\n",
    "        data = sorted_data[:sample_size]\n",
    "        print(f\"Selected first {sample_size} records after sorting.\")\n",
    "    questions = [x[\"question\"] for x in data]\n",
    "    ids = [x[\"id\"] for x in data]\n",
    "    return ids, questions\n",
    "\n",
    "def load_few_shot_prompt(prompt_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Loads the few-shot prompt from a text file.\n",
    "    \"\"\"\n",
    "    with open(prompt_path, 'r') as file:\n",
    "        prompt = file.read()\n",
    "    # print(f\"Loaded few-shot prompt from: {prompt_path}\")\n",
    "    return prompt\n",
    "\n",
    "def load_already_answered_ids(save_path: str) -> set:\n",
    "    \"\"\"\n",
    "    Loads the set of IDs that have already been answered from the CSV file.\n",
    "    Returns an empty set if the file does not exist.\n",
    "    \"\"\"\n",
    "    if os.path.exists(save_path):\n",
    "        df = pd.read_csv(save_path)\n",
    "        answered_ids = set(df['id'].astype(int).tolist())\n",
    "        # print(f\"Loaded {len(answered_ids)} already answered IDs from: {save_path}\")\n",
    "        print(f\"Already answered IDs: {answered_ids}\")\n",
    "        return answered_ids\n",
    "    else:\n",
    "        print(f\"No existing save file found at: {save_path}. Starting fresh.\")\n",
    "        return set()\n",
    "\n",
    "def initialize_save_file(save_path: str):\n",
    "    \"\"\"\n",
    "    Initializes the CSV file with headers if it doesn't exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        # Create an empty DataFrame with headers and save\n",
    "        df = pd.DataFrame(columns=['id', 'question', 'answer'])\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"Initialized new save file with headers at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1319 records from: /Users/log/Github/textual_grounding/data/GSM8K/test.jsonl\n",
      "Selected first 200 records after sorting.\n",
      "Already answered IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already answered ID: 0\n",
      "Skipping already answered ID: 1\n",
      "Skipping already answered ID: 2\n",
      "Skipping already answered ID: 3\n",
      "Skipping already answered ID: 4\n",
      "Skipping already answered ID: 5\n",
      "Skipping already answered ID: 6\n",
      "Skipping already answered ID: 7\n",
      "Skipping already answered ID: 8\n",
      "Skipping already answered ID: 9\n",
      "Skipping already answered ID: 10\n",
      "Skipping already answered ID: 11\n",
      "Skipping already answered ID: 12\n",
      "Skipping already answered ID: 13\n",
      "Skipping already answered ID: 14\n",
      "Skipping already answered ID: 15\n",
      "Skipping already answered ID: 16\n",
      "Skipping already answered ID: 17\n",
      "Skipping already answered ID: 18\n",
      "getting key from 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727592990.556221 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      " 10%|█         | 20/200 [00:06<00:58,  3.07it/s]I0000 00:00:1727592997.079952 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already answered ID: 20\n",
      "getting key from 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [00:10<01:37,  1.83it/s]I0000 00:00:1727593001.277159 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [00:16<02:48,  1.05it/s]I0000 00:00:1727593006.749806 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already answered ID: 23\n",
      "getting key from 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [00:19<03:13,  1.11s/it]I0000 00:00:1727593010.291306 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [00:26<05:05,  1.75s/it]I0000 00:00:1727593016.826085 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [01:20<27:02,  9.38s/it]I0000 00:00:1727593070.909620 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [01:25<24:53,  8.68s/it]I0000 00:00:1727593076.241424 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [01:30<22:24,  7.86s/it]I0000 00:00:1727593080.773128 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [01:34<19:57,  7.04s/it]I0000 00:00:1727593084.913776 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [01:39<18:34,  6.60s/it]I0000 00:00:1727593090.092361 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [02:39<56:27, 20.17s/it]I0000 00:00:1727593149.969195 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/200 [02:43<43:52, 15.76s/it]I0000 00:00:1727593153.625955 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [02:48<35:34, 12.86s/it]I0000 00:00:1727593158.874602 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 35/200 [02:52<28:47, 10.47s/it]I0000 00:00:1727593163.275016 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/200 [03:07<32:20, 11.83s/it]I0000 00:00:1727593178.488944 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/200 [03:11<25:54,  9.54s/it]I0000 00:00:1727593182.440245 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38/200 [03:15<20:59,  7.78s/it]I0000 00:00:1727593185.981487 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39/200 [03:20<18:25,  6.87s/it]I0000 00:00:1727593190.676827 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [03:26<17:57,  6.74s/it]I0000 00:00:1727593197.108460 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [04:22<56:52, 21.46s/it]I0000 00:00:1727593253.287021 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42/200 [04:27<43:32, 16.53s/it]I0000 00:00:1727593258.238063 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 43/200 [04:31<33:30, 12.80s/it]I0000 00:00:1727593262.297670 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44/200 [04:39<29:40, 11.42s/it]I0000 00:00:1727593270.458611 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 45/200 [04:45<24:59,  9.68s/it]I0000 00:00:1727593276.068699 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 46/200 [05:10<36:57, 14.40s/it]I0000 00:00:1727593301.511783 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [05:15<29:04, 11.40s/it]I0000 00:00:1727593305.915301 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [05:20<24:06,  9.51s/it]I0000 00:00:1727593311.015388 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/200 [05:23<19:05,  7.59s/it]I0000 00:00:1727593314.109617 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [05:27<16:21,  6.54s/it]I0000 00:00:1727593318.203869 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [06:16<47:31, 19.14s/it]I0000 00:00:1727593366.749453 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/200 [06:19<35:41, 14.47s/it]I0000 00:00:1727593370.326703 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/200 [06:24<28:21, 11.57s/it]I0000 00:00:1727593375.140681 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54/200 [06:36<28:41, 11.79s/it]I0000 00:00:1727593387.426216 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 55/200 [06:43<24:37, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question 54: Timeout of 60.0s exceeded, last exception: 429 Resource has been exhausted (e.g. check quota).\n",
      "getting key from 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727593393.879657 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      " 28%|██▊       | 56/200 [06:46<19:37,  8.18s/it]I0000 00:00:1727593397.358140 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [06:50<16:11,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question 56: Timeout of 60.0s exceeded, last exception: 429 Resource has been exhausted (e.g. check quota).\n",
      "getting key from 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727593400.931338 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      " 29%|██▉       | 58/200 [06:51<11:55,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question 57: Timeout of 60.0s exceeded, last exception: 429 Resource has been exhausted (e.g. check quota).\n",
      "getting key from 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727593401.865036 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      " 30%|██▉       | 59/200 [07:05<18:37,  7.93s/it]I0000 00:00:1727593416.534430 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [07:09<15:08,  6.49s/it]I0000 00:00:1727593419.683362 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [07:13<13:28,  5.82s/it]I0000 00:00:1727593423.922787 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [07:17<12:09,  5.29s/it]I0000 00:00:1727593427.978034 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63/200 [07:22<12:01,  5.27s/it]I0000 00:00:1727593433.196449 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting key from 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64/200 [07:39<19:38,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question 63: Timeout of 60.0s exceeded, last exception: 429 Resource has been exhausted (e.g. check quota).\n",
      "getting key from 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727593449.789357 29728448 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      " 32%|███▏      | 64/200 [07:47<16:33,  7.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/grpc/_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1175\u001b[0m (\n\u001b[1;32m   1176\u001b[0m     state,\n\u001b[1;32m   1177\u001b[0m     call,\n\u001b[1;32m   1178\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1180\u001b[0m )\n\u001b[0;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Resource has been exhausted (e.g. check quota).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:173.194.219.95:443 {created_time:\"2024-09-29T02:04:09.914019-05:00\", grpc_status:8, grpc_message:\"Resource has been exhausted (e.g. check quota).\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m target()\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m initialize_save_file(save_path)\n\u001b[1;32m     26\u001b[0m already_answered_ids \u001b[38;5;241m=\u001b[39m load_already_answered_ids(save_path)\n\u001b[0;32m---> 29\u001b[0m ids_answered, questions_answered, answers \u001b[38;5;241m=\u001b[39m query_llm(\n\u001b[1;32m     30\u001b[0m     llm_model\u001b[38;5;241m=\u001b[39mllm_model,\n\u001b[1;32m     31\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m     32\u001b[0m     questions\u001b[38;5;241m=\u001b[39mquestions,\n\u001b[1;32m     33\u001b[0m     few_shot_prompt\u001b[38;5;241m=\u001b[39mfew_shot_prompt,\n\u001b[1;32m     34\u001b[0m     prompt_type\u001b[38;5;241m=\u001b[39mprompt_type,\n\u001b[1;32m     35\u001b[0m     save_path\u001b[38;5;241m=\u001b[39msave_path,\n\u001b[1;32m     36\u001b[0m     already_answered_ids\u001b[38;5;241m=\u001b[39malready_answered_ids\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing complete. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids_answered)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m new answers saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[101], line 94\u001b[0m, in \u001b[0;36mquery_llm\u001b[0;34m(llm_model, ids, questions, few_shot_prompt, prompt_type, save_path, already_answered_ids)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llm_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m         answer \u001b[38;5;241m=\u001b[39m query_gemini(prompt, \u001b[38;5;28mid\u001b[39m)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m llm_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclaude\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     96\u001b[0m         answer \u001b[38;5;241m=\u001b[39m query_claude(prompt)\n",
      "Cell \u001b[0;32mIn[101], line 59\u001b[0m, in \u001b[0;36mquery_gemini\u001b[0;34m(prompt, problem_id)\u001b[0m\n\u001b[1;32m     57\u001b[0m genai\u001b[38;5;241m.\u001b[39mconfigure(api_key\u001b[38;5;241m=\u001b[39mget_gemini_key(problem_id))\n\u001b[1;32m     58\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini-1.5-pro-latest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(prompt, request_options\u001b[38;5;241m=\u001b[39mRequestOptions(retry\u001b[38;5;241m=\u001b[39mretry\u001b[38;5;241m.\u001b[39mRetry(initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, maximum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m121\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m)))\n\u001b[1;32m     60\u001b[0m text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m    332\u001b[0m             request,\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:827\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    826\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 827\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[1;32m    828\u001b[0m     request,\n\u001b[1;32m    829\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[1;32m    830\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    831\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m    832\u001b[0m )\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    294\u001b[0m     target,\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[1;32m    296\u001b[0m     sleep_generator,\n\u001b[1;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[1;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[1;32m    299\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:164\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         _retry_error_helper(\n\u001b[1;32m    154\u001b[0m             exc,\n\u001b[1;32m    155\u001b[0m             deadline,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m             timeout,\n\u001b[1;32m    162\u001b[0m         )\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(sleep)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSleep generator stopped yielding sleep values.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# time = datetime.datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "time = '0929_010513'\n",
    "project_root = '/Users/log/Github/textual_grounding/'\n",
    "dataset = 'GSM8K'\n",
    "\n",
    "# llm_model = 'llama3.1'\n",
    "llm_model = 'gemini'\n",
    "prompt_type = 'mermaid_get_answer'\n",
    "# prompt_type = 'cot'\n",
    "few_shot_txt = 'fewshot_mermaid_full.txt'\n",
    "# few_shot_txt = '3shot_cot.txt'\n",
    "\n",
    "# Paths\n",
    "data_path = os.path.join(project_root, 'data', dataset, 'test.jsonl')\n",
    "# data_path = '/Users/log/Github/textual_grounding/logan/results/GSM8K/llama/mermaid/mermaid_get_graph_llama3.1_20240924_001821.csv'\n",
    "\n",
    "fewshot_prompt_path = os.path.join(project_root, \"prompt\", dataset, few_shot_txt)\n",
    "save_dir = os.path.join(project_root, 'logan/results', dataset, f'{llm_model}/mermaid')\n",
    "os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists\n",
    "save_path = os.path.join(save_dir, f'{prompt_type}_{llm_model}_{time}.csv')\n",
    "\n",
    "ids, questions = load_data_deterministic(data_path, sample_size=200)  # Set sample_size as needed\n",
    "few_shot_prompt = load_few_shot_prompt(fewshot_prompt_path)\n",
    "\n",
    "initialize_save_file(save_path)\n",
    "already_answered_ids = load_already_answered_ids(save_path)\n",
    "\n",
    "\n",
    "ids_answered, questions_answered, answers = query_llm(\n",
    "    llm_model=llm_model,\n",
    "    ids=ids,\n",
    "    questions=questions,\n",
    "    few_shot_prompt=few_shot_prompt,\n",
    "    prompt_type=prompt_type,\n",
    "    save_path=save_path,\n",
    "    already_answered_ids=already_answered_ids\n",
    ")\n",
    "\n",
    "print(f\"Processing complete. {len(ids_answered)} new answers saved to {save_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML - visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML content has been successfully written to test_grounding_answer_prompt_fs_xml_llama3.1.html\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def extract_parts_1(answer_text):\n",
    "    \"\"\"\n",
    "    Processes the answer text to extract key facts (with numbers), answer reasoning, and the final answer.\n",
    "\n",
    "    Args:\n",
    "        answer_text (str): The full answer text containing <key_facts>, <answer_reasoning>, and <final_answer>.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (key_facts_list, answer_reasoning, final_answer)\n",
    "               where key_facts_list is a list of tuples (fact_number, fact_content)\n",
    "    \"\"\"\n",
    "    # Extract key_facts\n",
    "    key_facts_match = re.search(r'<key_facts>(.*?)</key_facts>', answer_text, re.DOTALL)\n",
    "    key_facts_content = key_facts_match.group(1).strip() if key_facts_match else \"\"\n",
    "\n",
    "    # Extract individual facts with their numbers\n",
    "    facts = re.findall(r'<fact_(\\d+)>(.*?)</fact_\\d+>', key_facts_content, re.DOTALL)\n",
    "    key_facts_list = [(number.strip(), content.strip()) for number, content in facts]\n",
    "\n",
    "    # Extract answer_reasoning\n",
    "    reasoning_match = re.search(r'<answer_reasoning>(.*?)</answer_reasoning>', answer_text, re.DOTALL)\n",
    "    answer_reasoning = reasoning_match.group(1).strip() if reasoning_match else \"\"\n",
    "\n",
    "    # Extract final_answer\n",
    "    final_match = re.search(r'<final_answer>(.*?)</final_answer>', answer_text, re.DOTALL)\n",
    "    final_answer = final_match.group(1).strip() if final_match else \"\"\n",
    "\n",
    "    return key_facts_list, answer_reasoning, final_answer\n",
    "\n",
    "\n",
    "def add_color_to_tags(text):\n",
    "    \"\"\"\n",
    "    Adds background color to specific tags within the text based on a predefined color mapping.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text containing tags like <fact_1>, <fact_2>, etc.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with added inline CSS for background colors.\n",
    "    \"\"\"\n",
    "    tag_color_mapping = {\n",
    "        'fact_1': 'yellow',  \n",
    "        'fact_2': 'lightblue',\n",
    "        'fact_3': 'lightgreen',\n",
    "        'fact_4': 'lightcoral',\n",
    "        'fact_5': 'lightcyan', \n",
    "        'fact_6': 'orange',\n",
    "    }\n",
    "    # Iterate over the tag-color mappings\n",
    "    for tag, color in tag_color_mapping.items():\n",
    "        # Regex to find the tag and replace it with the same tag having a style attribute\n",
    "        text = re.sub(\n",
    "            f'<{tag}>(.*?)</{tag}>',\n",
    "            f'<{tag} style=\"background-color: {color};\">\\\\1</{tag}>',\n",
    "            text,\n",
    "            flags=re.DOTALL\n",
    "        )\n",
    "    return text\n",
    "\n",
    "\n",
    "def parse_csv_file(file_path):\n",
    "    \"\"\"\n",
    "    Parses the input CSV file and extracts questions and their corresponding answers.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input CSV file.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (question, answer_text).\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            question = row.get('question', 'No question found.').strip()\n",
    "            answer_text = row.get('answer', 'No answer found.').strip()\n",
    "            qa_pairs.append((question, answer_text))\n",
    "    return qa_pairs\n",
    "\n",
    "\n",
    "def create_highlight_html(qa_pairs):\n",
    "    \"\"\"\n",
    "    Creates HTML content with highlighted questions, key facts, answer reasoning, and answers.\n",
    "\n",
    "    Args:\n",
    "        qa_pairs (list of tuples): Each tuple contains (question, answer_text).\n",
    "\n",
    "    Returns:\n",
    "        str: The complete HTML content as a string.\n",
    "    \"\"\"\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Question and Answer Highlights</title>\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "                margin: 20px;\n",
    "                background-color: #f0f0f0;\n",
    "            }\n",
    "            .container {\n",
    "                background-color: #ffffff;\n",
    "                padding: 20px;\n",
    "                margin-bottom: 20px;\n",
    "                border-radius: 8px;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            .question {\n",
    "                font-size: 1.2em;\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .key-facts {\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .key-facts ul {\n",
    "                list-style-type: number;\n",
    "                padding-left: 20px;\n",
    "            }\n",
    "            .key-facts ul li{\n",
    "                margin-bottom: 4px;\n",
    "            }\n",
    "            .answer-reasoning, .final-answer {\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .highlight {\n",
    "                background-color: #FFFF00; /* Yellow background for visibility */\n",
    "                font-weight: bold; /* Bold text for emphasis */\n",
    "            }\n",
    "            /* Styles for specific facts */\n",
    "            fact_1 {\n",
    "                background-color: yellow;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            fact_2 {\n",
    "                background-color: lightblue;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            fact_3 {\n",
    "                background-color: lightgreen;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            fact_4 {\n",
    "                background-color: lightcoral;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            fact_5 {\n",
    "                background-color: lightcyan;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            fact_6 {\n",
    "                background-color: orange;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>Question and Answer Highlights</h1>\n",
    "    \"\"\"\n",
    "    for i, (question, answer_text) in enumerate(qa_pairs, 1):\n",
    "        try:\n",
    "            key_facts, answer_reasoning, final_answer = extract_parts_1(answer_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Cannot extract parts for question {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Convert key_facts list to HTML bullet points with \"Key fact X:\" prefix\n",
    "        if key_facts:\n",
    "            key_facts_html = \"<ul>\\n\"\n",
    "            for fact_number, fact_content in key_facts:\n",
    "                # Apply color to tags in fact_content\n",
    "                highlighted_fact = add_color_to_tags(fact_content)\n",
    "                # Prepend \"Key fact X:\"\n",
    "                key_facts_html += f\"    <li><fact_{fact_number}>{highlighted_fact}</fact_{fact_number}></li>\\n\"\n",
    "            key_facts_html += \"</ul>\"\n",
    "        else:\n",
    "            key_facts_html = \"<p>No key facts available.</p>\"\n",
    "\n",
    "        # Apply color to tags in answer_reasoning and final_answer\n",
    "        highlighted_reasoning = add_color_to_tags(answer_reasoning)\n",
    "        highlighted_final_answer = add_color_to_tags(final_answer)\n",
    "\n",
    "        # Build the HTML structure\n",
    "        html_content += f\"<div class='container'>\"\n",
    "        html_content += f\"<div class='question'><strong>Question:</strong> {question}</div>\"\n",
    "        html_content += f\"<div class='key-facts'><strong>Key Facts:</strong> {key_facts_html}</div>\"\n",
    "        html_content += f\"<div class='answer-reasoning'><strong>Answer Reasoning:</strong> {highlighted_reasoning}</div>\"\n",
    "        html_content += f\"<div class='final-answer'><strong>Answer:</strong> {highlighted_final_answer}</div>\"\n",
    "        html_content += \"</div>\\n\"\n",
    "\n",
    "    # Close the HTML tags\n",
    "    html_content += \"\"\"\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html_content\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_file = '/Users/log/Github/textual_grounding/logan/results/GSM8K/llama/test_grounding_answer_prompt_fs_xml_llama3.1.csv'  # Replace with your input CSV file path\n",
    "    output_file = 'test_grounding_answer_prompt_fs_xml_llama3.1.html'  # Replace with your desired output HTML file path\n",
    "\n",
    "    # Parse the input CSV file to extract questions and answers\n",
    "    qa_pairs = parse_csv_file(input_file)\n",
    "\n",
    "    # Check if any QA pairs were found\n",
    "    if not qa_pairs:\n",
    "        print(\"No question-answer pairs were found in the input file.\")\n",
    "        return\n",
    "\n",
    "    # Generate the HTML content\n",
    "    html_content = create_highlight_html(qa_pairs)\n",
    "\n",
    "    # Write the HTML content to the output file\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"HTML content has been successfully written to {output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mermaid - Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total QA Pairs Parsed: 200\n",
      "No ground truth answer found for ID 489\n",
      "No ground truth answer found for ID 1113\n",
      "Total Ground Truth Entries: 1317\n",
      "HTML content has been successfully written to mm3_llama3.1.html\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import json  # For handling JSONL\n",
    "import os\n",
    "\n",
    "def extract_parts_new_format(answer_text):\n",
    "    \"\"\"\n",
    "    Processes the answer text to extract Mermaid diagrams, answer reasoning, and the final answer.\n",
    "\n",
    "    Args:\n",
    "        answer_text (str): The full answer text containing Mermaid diagrams, answer reasoning, and final answer.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (mermaid_diagrams, answer_reasoning, final_answer)\n",
    "               where mermaid_diagrams is a list of Mermaid diagram strings\n",
    "    \"\"\"\n",
    "    # Extract Mermaid diagrams\n",
    "    mermaid_diagrams = re.findall(r'```mermaid\\s*(.*?)```', answer_text, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    # Remove Mermaid diagrams from the answer_text to process the remaining text\n",
    "    answer_text_clean = re.sub(r'```mermaid\\s*.*?```', '', answer_text, flags=re.DOTALL | re.IGNORECASE).strip()\n",
    "\n",
    "    # Extract answer_reasoning: Take everything after the last indented line\n",
    "    # An indented line starts with spaces or tabs\n",
    "    indented_lines = list(re.finditer(r'^[ \\t]+.*$', answer_text_clean, re.MULTILINE))\n",
    "    if indented_lines:\n",
    "        last_indented = indented_lines[-1]\n",
    "        reasoning_start = last_indented.end()\n",
    "        answer_reasoning = answer_text_clean[reasoning_start:].strip()\n",
    "    else:\n",
    "        # If no indented lines are found, fallback to extracting everything after the first line\n",
    "        parts = answer_text_clean.split('\\n', 1)\n",
    "        answer_reasoning = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "\n",
    "    # Extract final_answer: Any number between {curly braces}\n",
    "    final_match = re.search(r'\\{([\\d,.\\-]+)\\}', answer_text_clean)\n",
    "    final_answer = final_match.group(1).replace(',', '') if final_match else \"\"\n",
    "\n",
    "    return mermaid_diagrams, answer_reasoning, final_answer\n",
    "\n",
    "def add_color_to_tags_new(text):\n",
    "    \"\"\"\n",
    "    Adds background color to specific tags within the text based on dynamically assigned colors.\n",
    "    Each span will have a class corresponding to the tag's name.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text containing tags like <B>, <C1>, etc.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with added inline CSS for background colors and class names.\n",
    "    \"\"\"\n",
    "    # Find all unique tags in the text using regex\n",
    "    # This regex matches tags like <B>, <C1>, <Node123>, etc.\n",
    "    tags = set(re.findall(r'<([A-Za-z]+\\d*)>', text))\n",
    "\n",
    "    # Predefined color palette\n",
    "    color_palette = [\n",
    "        'lightyellow', 'lightblue', 'lightgreen', 'lightcoral',\n",
    "        'lightcyan', 'lightpink', 'lightsalmon', 'lightgray',\n",
    "        'lightgoldenrodyellow', 'lightseagreen', 'lightskyblue',\n",
    "        'lightsteelblue'\n",
    "    ]\n",
    "\n",
    "    # Dictionary to hold tag-color mapping\n",
    "    tag_color_mapping = {}\n",
    "\n",
    "    # Assign colors to tags, cycling through the color palette if necessary\n",
    "    for i, tag in enumerate(sorted(tags)):\n",
    "        color = color_palette[i % len(color_palette)]\n",
    "        tag_color_mapping[tag] = color\n",
    "\n",
    "    # Function to replace tags with styled spans including class names\n",
    "    def replace_tag(match):\n",
    "        tag = match.group(1)\n",
    "        content = match.group(2)\n",
    "        color = tag_color_mapping.get(tag, 'lightgray')  # Default color if not found\n",
    "        return f'<span class=\"{tag}\" style=\"background-color: {color}; font-weight: bold;\">{content}</span>'\n",
    "\n",
    "    # Regex to find tags and replace them with styled spans\n",
    "    # This regex matches <Tag>Content</Tag> or <Tag> Content </Tag>\n",
    "    text = re.sub(r'<([A-Za-z]+\\d*)>\\s*(.*?)\\s*</\\1>', replace_tag, text, flags=re.DOTALL)\n",
    "\n",
    "    return text\n",
    "\n",
    "def parse_csv_file(file_path):\n",
    "    \"\"\"\n",
    "    Parses the input CSV file and extracts questions, answers, and their corresponding IDs.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input CSV file.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (id, question, answer_text).\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            question = row.get('question', 'No question found.').strip()\n",
    "            answer_text = row.get('answer', 'No answer found.').strip()\n",
    "            id_ = row.get('id')\n",
    "            if id_ is not None:\n",
    "                try:\n",
    "                    id_int = int(id_)\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping a row due to invalid 'id' (not an integer): {id_}\")\n",
    "                    continue\n",
    "                qa_pairs.append((id_int, question, answer_text))\n",
    "            else:\n",
    "                # Handle cases without 'id' by skipping\n",
    "                print(f\"Skipping a row due to missing 'id': {row}\")\n",
    "    return qa_pairs\n",
    "\n",
    "def read_ground_truth(jsonl_path):\n",
    "    \"\"\"\n",
    "    Reads the ground truth answers from a JSONL file and maps them by ID.\n",
    "\n",
    "    Args:\n",
    "        jsonl_path (str): Path to the ground truth JSONL file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each ID to its ground truth answer.\n",
    "    \"\"\"\n",
    "    ground_truth = {}\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            id_ = data.get('id')\n",
    "            answer = data.get('answer')\n",
    "            if id_ is not None and answer is not None:\n",
    "                # Extract the last number after '####' if present\n",
    "                match = re.search(r'####\\s*([\\d.]+)', answer)\n",
    "                if match:\n",
    "                    ground_truth[id_] = match.group(1).strip()\n",
    "                else:\n",
    "                    # If '####' not found, try to extract any number within {}\n",
    "                    match_braces = re.search(r'\\{([\\d,.\\-]+)\\}', answer)\n",
    "                    if match_braces:\n",
    "                        ground_truth[id_] = match_braces.group(1).replace(',', '').strip()\n",
    "                    else:\n",
    "                        print(f\"No ground truth answer found for ID {id_}\")\n",
    "            else:\n",
    "                print(f\"Invalid ground truth entry: {data}\")\n",
    "    return ground_truth\n",
    "\n",
    "def create_highlight_html_new(qa_pairs, ground_truth):\n",
    "    \"\"\"\n",
    "    Creates HTML content with Mermaid diagrams (both pure text and rendered), highlighted answer reasoning,\n",
    "    final answers colored based on correctness, and ground truth answers.\n",
    "\n",
    "    Args:\n",
    "        qa_pairs (list of tuples): Each tuple contains (id, question, answer_text).\n",
    "        ground_truth (dict): A dictionary mapping each ID to its ground truth answer.\n",
    "\n",
    "    Returns:\n",
    "        str: The complete HTML content as a string.\n",
    "    \"\"\"\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Question and Answer Highlights</title>\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "                margin: 20px;\n",
    "                background-color: #f0f0f0;\n",
    "            }\n",
    "            .container {\n",
    "                background-color: #ffffff;\n",
    "                padding: 20px;\n",
    "                margin-bottom: 20px;\n",
    "                border-radius: 8px;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            .question {\n",
    "                font-size: 1.2em;\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .mermaid {\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .mermaidPure {\n",
    "                background-color: #f9f9f9;\n",
    "                padding: 10px;\n",
    "                border: 1px solid #ddd;\n",
    "                border-radius: 4px;\n",
    "                white-space: pre-wrap; /* Preserves whitespace and newlines */\n",
    "                font-family: Consolas, \"Courier New\", monospace;\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .answer-reasoning, .final-answer, .ground-truth-answer {\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .final-answer {\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .ground-truth-answer {\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            /* Styles for the highlighted spans */\n",
    "            .highlighted {\n",
    "                padding: 2px 4px;\n",
    "                border-radius: 3px;\n",
    "                display: inline-block;\n",
    "            }\n",
    "            /* Styles for the summary section */\n",
    "            .summary {\n",
    "                background-color: #e0ffe0;\n",
    "                padding: 15px;\n",
    "                border: 2px solid #00cc00;\n",
    "                border-radius: 8px;\n",
    "                font-size: 1.2em;\n",
    "                margin-top: 30px;\n",
    "            }\n",
    "        </style>\n",
    "        <!-- Include Mermaid.js -->\n",
    "        <script type=\"module\">\n",
    "            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';\n",
    "            mermaid.initialize({ startOnLoad: true });\n",
    "        </script>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>Question and Answer Highlights</h1>\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize counters for correct and total answers\n",
    "    correct_answers = 0\n",
    "    total_answers = 0\n",
    "\n",
    "    for i, (id_, question, answer_text) in enumerate(qa_pairs, 1):\n",
    "        try:\n",
    "            mermaid_diagrams, answer_reasoning, final_answer = extract_parts_new_format(answer_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Cannot extract parts for question ID {id_}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Convert mermaid diagrams to HTML divs with pure text and rendered version\n",
    "        mermaid_html = \"\"\n",
    "        for diagram in mermaid_diagrams:\n",
    "            # Escape HTML special characters in the pure text version\n",
    "            escaped_diagram = diagram.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')\n",
    "            mermaid_html += f\"<div class='mermaidPure'><pre>{escaped_diagram}</pre></div>\\n\"\n",
    "            mermaid_html += f\"<div class='mermaid'>\\n{diagram}\\n</div>\\n\"\n",
    "\n",
    "        # Apply color to tags in answer_reasoning\n",
    "        highlighted_reasoning = add_color_to_tags_new(answer_reasoning)\n",
    "\n",
    "        # Retrieve ground truth answer\n",
    "        gt_answer = ground_truth.get(id_)\n",
    "        if gt_answer is None:\n",
    "            gt_answer_display = \"<span style='color: gray;'>Ground truth not available.</span>\"\n",
    "            is_correct = False\n",
    "        else:\n",
    "            # Normalize both final_answer and gt_answer for comparison\n",
    "            try:\n",
    "                final_answer_num = float(final_answer.replace(',', '').replace('$', ''))\n",
    "                gt_answer_num = float(gt_answer.replace(',', '').replace('$', ''))\n",
    "                is_correct = final_answer_num == gt_answer_num\n",
    "                final_answer_display = f\"{final_answer_num:,.2f}\"\n",
    "                gt_answer_display = f\"{gt_answer_num:,.2f}\"\n",
    "            except ValueError:\n",
    "                # In case conversion fails, fallback to string comparison\n",
    "                is_correct = final_answer == gt_answer\n",
    "                final_answer_display = final_answer\n",
    "                gt_answer_display = gt_answer\n",
    "\n",
    "        # Style the final answer based on correctness\n",
    "        if is_correct:\n",
    "            highlighted_final_answer = f\"<span style='font-size:1.1em; color: green;'>{final_answer_display}</span>\"\n",
    "            correct_answers += 1\n",
    "        else:\n",
    "            highlighted_final_answer = f\"<span style='font-size:1.1em; color: red;'>{final_answer_display}</span>\"\n",
    "        total_answers += 1\n",
    "\n",
    "        # Display ground truth answer\n",
    "        if gt_answer is not None:\n",
    "            ground_truth_html = f\"<div class='ground-truth-answer'><strong>Ground Truth Answer:</strong> {gt_answer_display}</div>\"\n",
    "        else:\n",
    "            ground_truth_html = f\"<div class='ground-truth-answer'><strong>Ground Truth Answer:</strong> Not available.</div>\"\n",
    "\n",
    "        # Build the HTML structure\n",
    "        html_content += f\"<div class='container'>\"\n",
    "        html_content += f\"<div class='question'><strong>Question:</strong> {question}</div>\"\n",
    "        if mermaid_html:\n",
    "            html_content += f\"{mermaid_html}\"\n",
    "        else:\n",
    "            html_content += f\"<p>No diagram available.</p>\"\n",
    "        html_content += f\"<div class='answer-reasoning'><strong>Answer Reasoning:</strong> {highlighted_reasoning}</div>\"\n",
    "        html_content += f\"<div class='final-answer'><strong>Final Answer:</strong> {highlighted_final_answer}</div>\"\n",
    "        html_content += f\"{ground_truth_html}\"\n",
    "        html_content += \"</div>\\n\"\n",
    "\n",
    "    # After processing all QA pairs, add the summary section\n",
    "    summary_percentage = (correct_answers / total_answers * 100) if total_answers > 0 else 0\n",
    "    summary_html = f\"\"\"\n",
    "    <div class='summary'>\n",
    "        <strong>Summary:</strong> Correct Answers: {correct_answers} / {total_answers} ({summary_percentage:.2f}%)\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    html_content = summary_html + html_content\n",
    "\n",
    "    # Close the HTML tags\n",
    "    html_content += \"\"\"\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html_content\n",
    "\n",
    "def main():\n",
    "    input_csv = '/Users/log/Github/textual_grounding/logan/results/GSM8K/llama/mermaid/mermaid_get_answer_llama3.1_20240926_215344.csv'  # Replace with your input CSV file path\n",
    "    ground_truth_file = '/Users/log/Github/textual_grounding/data/GSM8K/test.jsonl'  # Path to the ground truth JSONL file\n",
    "    output_file = 'mm3_llama3.1.html'  # Replace with your desired output HTML file path\n",
    "\n",
    "    # Check if input files exist\n",
    "    if not os.path.isfile(input_csv):\n",
    "        print(f\"Input CSV file not found: {input_csv}\")\n",
    "        return\n",
    "    if not os.path.isfile(ground_truth_file):\n",
    "        print(f\"Ground truth JSONL file not found: {ground_truth_file}\")\n",
    "        return\n",
    "\n",
    "    # Parse the input CSV file to extract IDs, questions, and answers\n",
    "    qa_pairs = parse_csv_file(input_csv)\n",
    "    print(f\"Total QA Pairs Parsed: {len(qa_pairs)}\")  # Debug: Print the number of QA pairs parsed\n",
    "\n",
    "    # Read the ground truth answers\n",
    "    ground_truth = read_ground_truth(ground_truth_file)\n",
    "    print(f\"Total Ground Truth Entries: {len(ground_truth)}\")  # Debug: Print the number of ground truth entries\n",
    "\n",
    "    # Check if any QA pairs were found\n",
    "    if not qa_pairs:\n",
    "        print(\"No question-answer pairs were found in the input file.\")\n",
    "        return\n",
    "\n",
    "    # Generate the HTML content\n",
    "    html_content = create_highlight_html_new(qa_pairs, ground_truth)\n",
    "\n",
    "    # Write the HTML content to the output file\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"HTML content has been successfully written to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoT - Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total QA Pairs Parsed: 200\n",
      "No ground truth answer found for ID 489\n",
      "No ground truth answer found for ID 1113\n",
      "Total Ground Truth Entries: 1317\n",
      "HTML content has been successfully written to cot_llama3.1.html\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import json  # For handling JSONL\n",
    "import os\n",
    "\n",
    "def extract_parts_regular_cot(answer_text):\n",
    "    \"\"\"\n",
    "    Processes the answer text to extract answer reasoning and the final answer.\n",
    "\n",
    "    Args:\n",
    "        answer_text (str): The full answer text containing answer reasoning and final answer.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (answer_reasoning, final_answer)\n",
    "               where answer_reasoning is the full model response,\n",
    "               and final_answer is the extracted answer.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fallback: Extract Final Answer from '{...}' in the reasoning\n",
    "    curly_match = re.search(r'\\{([\\d.]+)\\}', answer_text)\n",
    "    final_answer = curly_match.group(1).strip() if curly_match else \"\"\n",
    "\n",
    "    return answer_text.strip(), final_answer\n",
    "\n",
    "\n",
    "def add_color_to_tags_new(text):\n",
    "    \"\"\"\n",
    "    Adds background color to specific tags within the text based on dynamically assigned colors.\n",
    "    Each span will have a class corresponding to the tag's name.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text containing tags like <B>, <C1>, etc.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with added inline CSS for background colors and class names.\n",
    "    \"\"\"\n",
    "    # Find all unique tags in the text using regex\n",
    "    # This regex matches tags like <B>, <C1>, <Node123>, etc.\n",
    "    tags = set(re.findall(r'<([A-Za-z]+\\d*)>', text))\n",
    "\n",
    "    # Predefined color palette\n",
    "    color_palette = [\n",
    "        'lightyellow', 'lightblue', 'lightgreen', 'lightcoral',\n",
    "        'lightcyan', 'lightpink', 'lightsalmon', 'lightgray',\n",
    "        'lightgoldenrodyellow', 'lightseagreen', 'lightskyblue',\n",
    "        'lightsteelblue', 'lightsteelblue', 'lightsteelblue'\n",
    "    ]\n",
    "\n",
    "    # Dictionary to hold tag-color mapping\n",
    "    tag_color_mapping = {}\n",
    "\n",
    "    # Assign colors to tags, cycling through the color palette if necessary\n",
    "    for i, tag in enumerate(sorted(tags)):\n",
    "        color = color_palette[i % len(color_palette)]\n",
    "        tag_color_mapping[tag] = color\n",
    "\n",
    "    # Function to replace tags with styled spans including class names\n",
    "    def replace_tag(match):\n",
    "        tag = match.group(1)\n",
    "        content = match.group(2)\n",
    "        color = tag_color_mapping.get(tag, 'lightgray')  # Default color if not found\n",
    "        return f'<span class=\"{tag}\" style=\"background-color: {color}; font-weight: bold;\">{content}</span>'\n",
    "\n",
    "    # Regex to find tags and replace them with styled spans\n",
    "    # This regex matches <Tag>Content</Tag>\n",
    "    text = re.sub(r'<([A-Za-z]+\\d*)>(.*?)</\\1>', replace_tag, text, flags=re.DOTALL)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def parse_csv_file(file_path):\n",
    "    \"\"\"\n",
    "    Parses the input CSV file and extracts questions, answers, and their corresponding IDs.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input CSV file.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (id, question, answer_text).\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            question = row.get('question', 'No question found.').strip()\n",
    "            answer_text = row.get('answer', 'No answer found.').strip()\n",
    "            id_ = row.get('id')\n",
    "            if id_ is not None:\n",
    "                try:\n",
    "                    id_int = int(id_)\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping a row due to invalid 'id' (not an integer): {id_}\")\n",
    "                    continue\n",
    "                qa_pairs.append((id_int, question, answer_text))\n",
    "            else:\n",
    "                # Handle cases without 'id' by skipping\n",
    "                print(f\"Skipping a row due to missing 'id': {row}\")\n",
    "    return qa_pairs\n",
    "\n",
    "\n",
    "def read_ground_truth(jsonl_path):\n",
    "    \"\"\"\n",
    "    Reads the ground truth answers from a JSONL file and maps them by ID.\n",
    "\n",
    "    Args:\n",
    "        jsonl_path (str): Path to the ground truth JSONL file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each ID to its ground truth answer.\n",
    "    \"\"\"\n",
    "    ground_truth = {}\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            id_ = data.get('id')\n",
    "            answer = data.get('answer')\n",
    "            if id_ is not None and answer is not None:\n",
    "                # Extract the last number or text after '####'\n",
    "                match = re.search(r'####\\s*([\\d.]+)', answer)\n",
    "                if match:\n",
    "                    ground_truth[id_] = match.group(1).strip()\n",
    "                else:\n",
    "                    print(f\"No ground truth answer found for ID {id_}\")\n",
    "            else:\n",
    "                print(f\"Invalid ground truth entry: {data}\")\n",
    "    return ground_truth\n",
    "\n",
    "\n",
    "def create_highlight_html_new(qa_pairs, ground_truth):\n",
    "    \"\"\"\n",
    "    Creates HTML content with highlighted answer reasoning,\n",
    "    final answers colored based on correctness, and ground truth answers.\n",
    "\n",
    "    Args:\n",
    "        qa_pairs (list of tuples): Each tuple contains (id, question, answer_text).\n",
    "        ground_truth (dict): A dictionary mapping each ID to its ground truth answer.\n",
    "\n",
    "    Returns:\n",
    "        str: The complete HTML content as a string.\n",
    "    \"\"\"\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Question and Answer Highlights</title>\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "                margin: 20px;\n",
    "                background-color: #f0f0f0;\n",
    "            }\n",
    "            .container {\n",
    "                background-color: #ffffff;\n",
    "                padding: 20px;\n",
    "                margin-bottom: 20px;\n",
    "                border-radius: 8px;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            .question {\n",
    "                font-size: 1.2em;\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .answer-reasoning, .final-answer, .ground-truth-answer {\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .final-answer {\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .ground-truth-answer {\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            /* Styles for the highlighted spans */\n",
    "            .highlighted {\n",
    "                padding: 2px 4px;\n",
    "                border-radius: 3px;\n",
    "                display: inline-block;\n",
    "            }\n",
    "            /* Styles for the summary section */\n",
    "            .summary {\n",
    "                background-color: #e0ffe0;\n",
    "                padding: 15px;\n",
    "                border: 2px solid #00cc00;\n",
    "                border-radius: 8px;\n",
    "                font-size: 1.2em;\n",
    "                margin-bottom: 30px;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>Question and Answer Highlights</h1>\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize counters for correct and total answers\n",
    "    correct_answers = 0\n",
    "    total_answers = 0\n",
    "\n",
    "    # Placeholder for summary to be added at the top\n",
    "    summary_html = \"\"  # Will be updated after processing all QA pairs\n",
    "\n",
    "    # Temporary storage for all QA containers\n",
    "    qa_html_sections = \"\"\n",
    "\n",
    "    for i, (id_, question, answer_text) in enumerate(qa_pairs, 1):\n",
    "        try:\n",
    "            answer_reasoning, final_answer = extract_parts_regular_cot(answer_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Cannot extract parts for question ID {id_}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Apply color to tags in answer_reasoning\n",
    "        highlighted_reasoning = add_color_to_tags_new(answer_reasoning)\n",
    "\n",
    "        # Retrieve ground truth answer\n",
    "        gt_answer = ground_truth.get(id_)\n",
    "        if gt_answer is None:\n",
    "            gt_answer_display = \"<span style='color: gray;'>Ground truth not available.</span>\"\n",
    "            is_correct = False\n",
    "        else:\n",
    "            gt_answer_display = gt_answer\n",
    "            # Compare final_answer with ground truth\n",
    "            is_correct = final_answer == gt_answer\n",
    "\n",
    "        # Style the final answer based on correctness\n",
    "        if is_correct:\n",
    "            highlighted_final_answer = f\"<span style='font-size:1.1em; color: green;'>{final_answer}</span>\"\n",
    "            correct_answers += 1\n",
    "        else:\n",
    "            highlighted_final_answer = f\"<span style='font-size:1.1em; color: red;'>{final_answer}</span>\"\n",
    "        total_answers += 1\n",
    "\n",
    "        # Display ground truth answer\n",
    "        if gt_answer is not None:\n",
    "            ground_truth_html = f\"<div class='ground-truth-answer'><strong>Ground Truth Answer:</strong> {gt_answer_display}</div>\"\n",
    "        else:\n",
    "            ground_truth_html = f\"<div class='ground-truth-answer'><strong>Ground Truth Answer:</strong> Not available.</div>\"\n",
    "\n",
    "        # Build the HTML structure for this QA pair\n",
    "        qa_html_sections += f\"<div class='container'>\"\n",
    "        qa_html_sections += f\"<div class='question'><strong>Question:</strong> {question}</div>\"\n",
    "        qa_html_sections += f\"<div class='answer-reasoning'><strong>Answer Reasoning:</strong> {highlighted_reasoning}</div>\"\n",
    "        qa_html_sections += f\"<div class='final-answer'><strong>Final Answer:</strong> {highlighted_final_answer}</div>\"\n",
    "        qa_html_sections += f\"{ground_truth_html}\"\n",
    "        qa_html_sections += \"</div>\\n\"\n",
    "\n",
    "    # After processing all QA pairs, create the summary\n",
    "    accuracy_percentage = (correct_answers / total_answers * 100) if total_answers > 0 else 0\n",
    "    summary_html = f\"\"\"\n",
    "    <div class='summary'>\n",
    "        <strong>Summary:</strong> Correct Answers: {correct_answers} / {total_answers} ({accuracy_percentage:.2f}%)\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    # Append the summary at the top, right after the header\n",
    "    html_content += summary_html\n",
    "    html_content += qa_html_sections\n",
    "\n",
    "    # Close the HTML tags\n",
    "    html_content += \"\"\"\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html_content\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_csv = '/Users/log/Github/textual_grounding/logan/results/GSM8K/llama/mermaid/cot_llama3.1_20240927_003000.csv'  # Replace with your input CSV file path\n",
    "    ground_truth_file = '/Users/log/Github/textual_grounding/data/GSM8K/test.jsonl'  # Path to the ground truth JSONL file\n",
    "    output_file = 'cot_llama3.1.html'  # Replace with your desired output HTML file path\n",
    "\n",
    "    # Check if input files exist\n",
    "    if not os.path.isfile(input_csv):\n",
    "        print(f\"Input CSV file not found: {input_csv}\")\n",
    "        return\n",
    "    if not os.path.isfile(ground_truth_file):\n",
    "        print(f\"Ground truth JSONL file not found: {ground_truth_file}\")\n",
    "        return\n",
    "\n",
    "    # Parse the input CSV file to extract IDs, questions, and answers\n",
    "    qa_pairs = parse_csv_file(input_csv)\n",
    "    print(f\"Total QA Pairs Parsed: {len(qa_pairs)}\")  # Debug: Print the number of QA pairs parsed\n",
    "\n",
    "    # Read the ground truth answers\n",
    "    ground_truth = read_ground_truth(ground_truth_file)\n",
    "    print(f\"Total Ground Truth Entries: {len(ground_truth)}\")  # Debug: Print the number of ground truth entries\n",
    "\n",
    "    # Check if any QA pairs were found\n",
    "    if not qa_pairs:\n",
    "        print(\"No question-answer pairs were found in the input file.\")\n",
    "        return\n",
    "\n",
    "    # Generate the HTML content\n",
    "    html_content = create_highlight_html_new(qa_pairs, ground_truth)\n",
    "\n",
    "    # Write the HTML content to the output file\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"HTML content has been successfully written to {output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tin - visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML content has been successfully written to question_answer_highlights_prompt_fs_llama3.1.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Define the prompt_type and llm_model as needed\n",
    "prompt_type = \"fs\"  # Example value, set accordingly\n",
    "llm_model = \"llama3.1\"  # Example value, set accordingly\n",
    "\n",
    "save_html_path = f\"question_answer_highlights_prompt_{prompt_type}_{llm_model}.html\"\n",
    "# df_path = f'logan/results/{dataset}/llama/test_grounding_answer_prompt_{prompt_type}_{llm_model}.csv'\n",
    "df_path = '/Users/log/Github/textual_grounding/logan/results/GSM8K/llama/test_grounding_answer_prompt_fs_inst_llama3.1.csv'\n",
    "\n",
    "if prompt_type in [\"fs\", \"fs_inst\"]:\n",
    "    prefix = 'The answer is'\n",
    "elif prompt_type == \"zs\":\n",
    "    prefix = 'Final answer:'\n",
    "\n",
    "df = pd.read_csv(df_path)\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()\n",
    "\n",
    "def add_color_to_tags(text):\n",
    "    \"\"\"\n",
    "    Adds background color to specific tags within the text based on a predefined color mapping.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text containing tags like <a>, <b>, etc.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with added inline CSS for background colors.\n",
    "    \"\"\"\n",
    "    tag_color_mapping = {\n",
    "        'a': 'yellow',       # You can customize colors as needed\n",
    "        'b': 'lightblue',\n",
    "        'c': 'lightgreen',\n",
    "        'd': 'lightcoral',\n",
    "        'e': 'lightcyan',\n",
    "        'f': 'orange',       # Extend as needed\n",
    "        # Add more tags if necessary\n",
    "    }\n",
    "    # Iterate over the tag-color mappings\n",
    "    for tag, color in tag_color_mapping.items():\n",
    "        # Regex to find the tag and replace it with the same tag having a style attribute\n",
    "        text = re.sub(\n",
    "            f'<{tag}>(.*?)</{tag}>',\n",
    "            f'<span style=\"background-color: {color};\">{r\"\\1\"}</span>',\n",
    "            text,\n",
    "            flags=re.DOTALL\n",
    "        )\n",
    "    return text\n",
    "\n",
    "def parse_csv_file(file_path):\n",
    "    \"\"\"\n",
    "    Parses the input CSV file and extracts questions and their corresponding answers.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input CSV file.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (question, answer_text).\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            question = row.get('question', 'No question found.').strip()\n",
    "            answer_text = row.get('answer', 'No answer found.').strip()\n",
    "            qa_pairs.append((question, answer_text))\n",
    "    return qa_pairs\n",
    "\n",
    "def create_highlight_html(qa_pairs):\n",
    "    \"\"\"\n",
    "    Creates HTML content with highlighted questions and answers based on tags.\n",
    "\n",
    "    Args:\n",
    "        qa_pairs (list of tuples): Each tuple contains (question, answer_text).\n",
    "\n",
    "    Returns:\n",
    "        str: The complete HTML content as a string.\n",
    "    \"\"\"\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Question and Answer Highlights</title>\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "                margin: 20px;\n",
    "                background-color: #f0f0f0;\n",
    "            }\n",
    "            .container {\n",
    "                background-color: #ffffff;\n",
    "                padding: 20px;\n",
    "                margin-bottom: 20px;\n",
    "                border-radius: 8px;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            .question {\n",
    "                font-size: 1.2em;\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .answer {\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .highlight {\n",
    "                background-color: #FFFF00; /* Default highlight color */\n",
    "                font-weight: bold; /* Bold text for emphasis */\n",
    "            }\n",
    "            /* Additional styles for specific tags can be added here if needed */\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>Question and Answer Highlights</h1>\n",
    "    \"\"\"\n",
    "    for i, (question, answer_text) in enumerate(qa_pairs, 1):\n",
    "        try:\n",
    "            # Apply color to tags in question and answer\n",
    "            highlighted_question = add_color_to_tags(question)\n",
    "            highlighted_answer = add_color_to_tags(answer_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Cannot process question-answer pair {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Build the HTML structure\n",
    "        html_content += f\"<div class='container'>\"\n",
    "        html_content += f\"<div class='question'><strong>Question:</strong> {highlighted_question}</div>\"\n",
    "        html_content += f\"<div class='answer'><strong>Answer:</strong> {highlighted_answer}</div>\"\n",
    "        html_content += \"</div>\\n\"\n",
    "\n",
    "    # Close the HTML tags\n",
    "    html_content += \"\"\"\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html_content\n",
    "\n",
    "def main():\n",
    "    input_file = df_path  # Use the defined df_path\n",
    "    output_file = save_html_path  # Use the defined save_html_path\n",
    "\n",
    "    # Parse the input CSV file to extract questions and answers\n",
    "    qa_pairs = parse_csv_file(input_file)\n",
    "\n",
    "    # Check if any QA pairs were found\n",
    "    if not qa_pairs:\n",
    "        print(\"No question-answer pairs were found in the input file.\")\n",
    "        return\n",
    "\n",
    "    # Generate the HTML content\n",
    "    html_content = create_highlight_html(qa_pairs)\n",
    "\n",
    "    # Write the HTML content to the output file\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"HTML content has been successfully written to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total QA Pairs Parsed: 200\n",
      "No ground truth answer found for ID 489\n",
      "No ground truth answer found for ID 1113\n",
      "Total Ground Truth Entries: 1317\n",
      "\n",
      "===== Analysis Statistics =====\n",
      "\n",
      "Total Responses Analyzed: 200\n",
      "Responses with Final Answer in Curly Brackets: 136 (68.00%)\n",
      "Responses without Final Answer in Curly Brackets: 64 (32.00%)\n",
      "Responses with Ground Truth Available: 200 (100.00%)\n",
      "Correct Answers: 94\n",
      "Incorrect Answers: 106\n",
      "Accuracy: 47.00%\n",
      "Responses without Ground Truth: 0\n",
      "\n",
      "----- Tag Statistics -----\n",
      "Total Tags Found: 501\n",
      "Average Number of Tags per Response: 2.50\n",
      "Average Length of Tag Content: 8.68 characters\n",
      "--------------------------\n",
      "\n",
      "===== End of Statistics =====\n",
      "\n",
      "Statistics analysis completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import json  # For handling JSONL\n",
    "import os\n",
    "\n",
    "def extract_parts_regular_cot(answer_text):\n",
    "    \"\"\"\n",
    "    Processes the answer text to extract answer reasoning and the final answer.\n",
    "\n",
    "    Args:\n",
    "        answer_text (str): The full answer text containing answer reasoning and final answer.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (answer_reasoning, final_answer, has_curly)\n",
    "               where answer_reasoning is the full model response,\n",
    "               final_answer is the extracted answer,\n",
    "               and has_curly is a boolean indicating if the final answer was in curly brackets.\n",
    "    \"\"\"\n",
    "    # Attempt to extract Final Answer from 'Final Answer:'\n",
    "    final_match = re.search(r'Final Answer:\\s*(\\S+)', answer_text, re.IGNORECASE)\n",
    "    if final_match and final_match.group(1).strip():\n",
    "        final_answer = final_match.group(1).strip()\n",
    "        has_curly = False\n",
    "    else:\n",
    "        # Fallback: Extract Final Answer from '{...}' in the reasoning\n",
    "        curly_match = re.search(r'\\{([\\d.]+)\\}', answer_text)\n",
    "        final_answer = curly_match.group(1).strip() if curly_match else \"\"\n",
    "        has_curly = bool(curly_match)\n",
    "\n",
    "    return answer_text.strip(), final_answer, has_curly\n",
    "\n",
    "def parse_csv_file(file_path):\n",
    "    \"\"\"\n",
    "    Parses the input CSV file and extracts questions, answers, and their corresponding IDs.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input CSV file.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (id, question, answer_text).\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            question = row.get('question', 'No question found.').strip()\n",
    "            answer_text = row.get('answer', 'No answer found.').strip()\n",
    "            id_ = row.get('id')\n",
    "            if id_ is not None:\n",
    "                try:\n",
    "                    id_int = int(id_)\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping a row due to invalid 'id' (not an integer): {id_}\")\n",
    "                    continue\n",
    "                qa_pairs.append((id_int, question, answer_text))\n",
    "            else:\n",
    "                # Handle cases without 'id' by skipping\n",
    "                print(f\"Skipping a row due to missing 'id': {row}\")\n",
    "    return qa_pairs\n",
    "\n",
    "def read_ground_truth(jsonl_path):\n",
    "    \"\"\"\n",
    "    Reads the ground truth answers from a JSONL file and maps them by ID.\n",
    "\n",
    "    Args:\n",
    "        jsonl_path (str): Path to the ground truth JSONL file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each ID to its ground truth answer.\n",
    "    \"\"\"\n",
    "    ground_truth = {}\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            id_ = data.get('id')\n",
    "            answer = data.get('answer')\n",
    "            if id_ is not None and answer is not None:\n",
    "                # Extract the last number or text after '####'\n",
    "                match = re.search(r'####\\s*([\\d.]+)', answer)\n",
    "                if match:\n",
    "                    ground_truth[id_] = match.group(1).strip()\n",
    "                else:\n",
    "                    print(f\"No ground truth answer found for ID {id_}\")\n",
    "            else:\n",
    "                print(f\"Invalid ground truth entry: {data}\")\n",
    "    return ground_truth\n",
    "\n",
    "def create_statistics(qa_pairs, ground_truth):\n",
    "    \"\"\"\n",
    "    Creates and prints statistics based on the QA pairs and ground truth.\n",
    "\n",
    "    Args:\n",
    "        qa_pairs (list of tuples): Each tuple contains (id, question, answer_text).\n",
    "        ground_truth (dict): A dictionary mapping each ID to its ground truth answer.\n",
    "    \"\"\"\n",
    "    total_responses = len(qa_pairs)\n",
    "    responses_with_curly = 0\n",
    "    responses_without_curly = 0\n",
    "    correct_answers = 0\n",
    "    incorrect_answers = 0\n",
    "    no_ground_truth = 0\n",
    "\n",
    "    # Variables for tag statistics\n",
    "    total_tags = 0\n",
    "    total_tag_length = 0\n",
    "    tag_counts = []  # List to store number of tags per response\n",
    "    tag_lengths = []  # List to store lengths of tag content across all responses\n",
    "\n",
    "    for id_, question, answer_text in qa_pairs:\n",
    "        try:\n",
    "            answer_reasoning, final_answer, has_curly = extract_parts_regular_cot(answer_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Cannot extract parts for question ID {id_}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if has_curly:\n",
    "            responses_with_curly += 1\n",
    "        else:\n",
    "            responses_without_curly += 1\n",
    "\n",
    "        # Extract tags and their content\n",
    "        tags_in_response = re.findall(r'<([A-Za-z]+\\d*)>(.*?)</\\1>', answer_text)\n",
    "        number_of_tags = len(tags_in_response)\n",
    "        tag_counts.append(number_of_tags)\n",
    "        total_tags += number_of_tags\n",
    "\n",
    "        for tag, content in tags_in_response:\n",
    "            content_length = len(content)\n",
    "            tag_lengths.append(content_length)\n",
    "            total_tag_length += content_length\n",
    "\n",
    "        # Retrieve ground truth answer\n",
    "        gt_answer = ground_truth.get(id_)\n",
    "        if gt_answer is None:\n",
    "            no_ground_truth += 1\n",
    "            continue\n",
    "\n",
    "        # Compare final_answer with ground truth\n",
    "        if final_answer == gt_answer:\n",
    "            correct_answers += 1\n",
    "        else:\n",
    "            incorrect_answers += 1\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    accuracy_percentage = (correct_answers / (correct_answers + incorrect_answers) * 100) if (correct_answers + incorrect_answers) > 0 else 0\n",
    "    curly_percentage = (responses_with_curly / total_responses * 100) if total_responses > 0 else 0\n",
    "    no_curly_percentage = (responses_without_curly / total_responses * 100) if total_responses > 0 else 0\n",
    "    ground_truth_available = total_responses - no_ground_truth\n",
    "    ground_truth_available_percentage = (ground_truth_available / total_responses * 100) if total_responses > 0 else 0\n",
    "\n",
    "    # Calculate tag statistics\n",
    "    average_tags_per_response = (total_tags / total_responses) if total_responses > 0 else 0\n",
    "    average_tag_length = (total_tag_length / total_tags) if total_tags > 0 else 0\n",
    "\n",
    "    # Print the statistics\n",
    "    print(\"\\n===== Analysis Statistics =====\\n\")\n",
    "    print(f\"Total Responses Analyzed: {total_responses}\")\n",
    "    print(f\"Responses with Final Answer in Curly Brackets: {responses_with_curly} ({curly_percentage:.2f}%)\")\n",
    "    print(f\"Responses without Final Answer in Curly Brackets: {responses_without_curly} ({no_curly_percentage:.2f}%)\")\n",
    "    print(f\"Responses with Ground Truth Available: {ground_truth_available} ({ground_truth_available_percentage:.2f}%)\")\n",
    "    print(f\"Correct Answers: {correct_answers}\")\n",
    "    print(f\"Incorrect Answers: {incorrect_answers}\")\n",
    "    print(f\"Accuracy: {accuracy_percentage:.2f}%\")\n",
    "    print(f\"Responses without Ground Truth: {no_ground_truth}\")\n",
    "\n",
    "    # Tag Statistics\n",
    "    print(\"\\n----- Tag Statistics -----\")\n",
    "    print(f\"Total Tags Found: {total_tags}\")\n",
    "    print(f\"Average Number of Tags per Response: {average_tags_per_response:.2f}\")\n",
    "    print(f\"Average Length of Tag Content: {average_tag_length:.2f} characters\")\n",
    "    print(\"--------------------------\\n\")\n",
    "    print(\"===== End of Statistics =====\\n\")\n",
    "\n",
    "def main():\n",
    "    input_csv = '/Users/log/Github/textual_grounding/logan/results/GSM8K/llama/mermaid/mermaid_get_answer_llama3.1_20240926_215344.csv'  # Replace with your input CSV file path\n",
    "    ground_truth_file = '/Users/log/Github/textual_grounding/data/GSM8K/test.jsonl'  # Path to the ground truth JSONL file\n",
    "\n",
    "    # Check if input files exist\n",
    "    if not os.path.isfile(input_csv):\n",
    "        print(f\"Input CSV file not found: {input_csv}\")\n",
    "        return\n",
    "    if not os.path.isfile(ground_truth_file):\n",
    "        print(f\"Ground truth JSONL file not found: {ground_truth_file}\")\n",
    "        return\n",
    "\n",
    "    # Parse the input CSV file to extract IDs, questions, and answers\n",
    "    qa_pairs = parse_csv_file(input_csv)\n",
    "    print(f\"Total QA Pairs Parsed: {len(qa_pairs)}\")  # Debug: Print the number of QA pairs parsed\n",
    "\n",
    "    # Read the ground truth answers\n",
    "    ground_truth = read_ground_truth(ground_truth_file)\n",
    "    print(f\"Total Ground Truth Entries: {len(ground_truth)}\")  # Debug: Print the number of ground truth entries\n",
    "\n",
    "    # Check if any QA pairs were found\n",
    "    if not qa_pairs:\n",
    "        print(\"No question-answer pairs were found in the input file.\")\n",
    "        return\n",
    "\n",
    "    # Generate and print the statistics\n",
    "    create_statistics(qa_pairs, ground_truth)\n",
    "\n",
    "    print(\"Statistics analysis completed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
