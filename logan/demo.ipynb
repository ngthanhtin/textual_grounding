{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ollama\n",
    "import google.generativeai as genai\n",
    "import anthropic\n",
    "import ollama\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from google.generativeai.types import RequestOptions\n",
    "from google.api_core import retry\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "import visualize\n",
    "import pandas as pd\n",
    "from utils.utils import add_color_to_tags, extract_parts_0, extract_parts_1\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl_file(filepath):\n",
    "    data = [] \n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line)  # Parse the JSON data from the line\n",
    "            data.append(json_obj)  # Add the parsed JSON object to a list\n",
    "    return data\n",
    "\n",
    "def get_prompt(prompt_type: str, few_shot_prompt: str, question: str) -> str:\n",
    "    prompts = {\n",
    "        \"fs\": f\"{few_shot_prompt}\\n{question}\",\n",
    "        \"fs_inst\": f\"{few_shot_prompt}\\n{question}\\nI want you to answer this question but your explanation should contain references referring back to the information in the question. To do that, first, re-generate the question with proper tags and then generate your answers. The output format is as follow:\\n\\\n",
    "            Reformatted Question: \\\n",
    "                Answer:\",\n",
    "        \"zs\": f\"{question}\\nI want you to answer this question but your explanation should contain references referring back to the information in the question. To do that, first, re-generate the question with proper tags (<a>, <b>, <c>, etc) for refered information and then generate your answers that also have the tag (<a>, <b>, <c>, etc) for the grounded information. Give your answer by analyzing step by step, and give only numbers in the final answer. The output format is as follow:\\n\\\n",
    "            Reformatted Question: \\\n",
    "                Answer:\\\n",
    "                    Final answer:\",\n",
    "        \"fs_xml\": f\"{few_shot_prompt}\\n\\nRecreate the following question in the style of the correctly formatted examples shown previously. Make sure that your response has all its information inclosed in the proper <tags>. Begin your response with the <key_facts> section. Make sure that every fact in <key_facts> is very concise and contains a very short reference to the <question>. Do not include a <question> section in your response\\n\\n<question>\\n{question}\\n</question>\"\n",
    "    }\n",
    "    return prompts.get(prompt_type, \"\")\n",
    "\n",
    "def query_gemini(prompt: str) -> str:\n",
    "    genai.configure(api_key=API_KEYS['gemini'])\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "    response = model.generate_content(prompt, request_options=RequestOptions(retry=retry.Retry(initial=10, multiplier=2, maximum=60, timeout=60)))\n",
    "    return response.text\n",
    "\n",
    "def query_claude(prompt: str) -> str:\n",
    "    client = anthropic.Anthropic(api_key=API_KEYS['claude'])\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=1024,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.content[0].text\n",
    "\n",
    "def query_llm(llm_model: str, ids: List[str], questions: List[str], few_shot_prompt: str, prompt_type: str) -> Tuple[List[str], List[str], List[str]]:\n",
    "    answers = []\n",
    "    ids_can_be_answered = []\n",
    "    questions_can_be_answered = []\n",
    "    \n",
    "    for id, q in tqdm(zip(ids, questions)):\n",
    "        prompt = get_prompt(prompt_type, few_shot_prompt, q)\n",
    "        # print(prompt)\n",
    "        try:\n",
    "            if llm_model == 'gemini':\n",
    "                answer = query_gemini(prompt)\n",
    "            elif llm_model == 'claude':\n",
    "                answer = query_claude(prompt)\n",
    "            elif llm_model == 'llama3.1':\n",
    "                answer = ollama.generate(model='llama3.1', prompt=prompt)['response']\n",
    "                print(answer)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported LLM model: {llm_model}\")\n",
    "            \n",
    "            answers.append(answer)\n",
    "            questions_can_be_answered.append(q)\n",
    "            ids_can_be_answered.append(id)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {id}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return ids_can_be_answered, questions_can_be_answered, answers\n",
    "\n",
    "def load_data(data_path: str, sample_size: int = None) -> Tuple[List[str], List[str]]:\n",
    "    data = read_jsonl_file(data_path)\n",
    "    print(data_path)\n",
    "    print(data)\n",
    "    if sample_size:\n",
    "        data = random.sample(data, sample_size)\n",
    "    questions = [x[\"question\"] for x in data]\n",
    "    ids = [x[\"id\"] for x in data]\n",
    "    return ids, questions\n",
    "\n",
    "def load_few_shot_prompt(prompt_path: str) -> str:\n",
    "    with open(prompt_path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "def save_results(save_path: str, ids: List[str], questions: List[str], answers: List[str]):\n",
    "    df = pd.DataFrame({'id': ids, 'question': questions, 'answer': answers})\n",
    "    df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = '/Users/log/Github/textual_grounding/'\n",
    "llm_model = 'llama3.1'\n",
    "dataset = 'GSM8K'\n",
    "# prompt_type = 'fs_xml'\n",
    "prompt_type = 'fs_inst'\n",
    "# few_shot_txt = 'fewshot_key_facts_xml.txt'\n",
    "few_shot_txt = 'fewshot_grounding_prompt_design_1_tin.txt'\n",
    "\n",
    "\n",
    "data_path = os.path.join(project_root, 'data', dataset, 'test.jsonl')\n",
    "fewshot_prompt_path = os.path.join(project_root, \"prompt\", dataset, few_shot_txt)\n",
    "save_path = os.path.join(project_root, 'logan/results', dataset, 'llama', f'test_grounding_answer_prompt_{prompt_type}_{llm_model}.csv')\n",
    "\n",
    "# Load data and prompt\n",
    "ids, questions = load_data(data_path, sample_size=4)\n",
    "few_shot_prompt = load_few_shot_prompt(fewshot_prompt_path)\n",
    "\n",
    "# Query LLM\n",
    "ids_answered, questions_answered, answers = query_llm(llm_model, ids, questions, few_shot_prompt, prompt_type)\n",
    "\n",
    "# Save results\n",
    "save_results(save_path, ids_answered, questions_answered, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML content has been successfully written to output.html\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def extract_parts_1(answer_text):\n",
    "    \"\"\"\n",
    "    Processes the answer text to extract key facts (with numbers), answer reasoning, and the final answer.\n",
    "\n",
    "    Args:\n",
    "        answer_text (str): The full answer text containing <key_facts>, <answer_reasoning>, and <final_answer>.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (key_facts_list, answer_reasoning, final_answer)\n",
    "               where key_facts_list is a list of tuples (fact_number, fact_content)\n",
    "    \"\"\"\n",
    "    # Extract key_facts\n",
    "    key_facts_match = re.search(r'<key_facts>(.*?)</key_facts>', answer_text, re.DOTALL)\n",
    "    key_facts_content = key_facts_match.group(1).strip() if key_facts_match else \"\"\n",
    "\n",
    "    # Extract individual facts with their numbers\n",
    "    facts = re.findall(r'<fact_(\\d+)>(.*?)</fact_\\d+>', key_facts_content, re.DOTALL)\n",
    "    key_facts_list = [(number.strip(), content.strip()) for number, content in facts]\n",
    "\n",
    "    # Extract answer_reasoning\n",
    "    reasoning_match = re.search(r'<answer_reasoning>(.*?)</answer_reasoning>', answer_text, re.DOTALL)\n",
    "    answer_reasoning = reasoning_match.group(1).strip() if reasoning_match else \"\"\n",
    "\n",
    "    # Extract final_answer\n",
    "    final_match = re.search(r'<final_answer>(.*?)</final_answer>', answer_text, re.DOTALL)\n",
    "    final_answer = final_match.group(1).strip() if final_match else \"\"\n",
    "\n",
    "    return key_facts_list, answer_reasoning, final_answer\n",
    "\n",
    "\n",
    "def add_color_to_tags(text):\n",
    "    \"\"\"\n",
    "    Adds background color to specific tags within the text based on a predefined color mapping.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text containing tags like <fact_1>, <fact_2>, etc.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with added inline CSS for background colors.\n",
    "    \"\"\"\n",
    "    tag_color_mapping = {\n",
    "        'fact_1': 'yellow',  \n",
    "        'fact_2': 'lightblue',\n",
    "        'fact_3': 'lightgreen',\n",
    "        'fact_4': 'lightcoral',\n",
    "        'fact_5': 'lightcyan', \n",
    "        'fact_6': 'orange',\n",
    "    }\n",
    "    # Iterate over the tag-color mappings\n",
    "    for tag, color in tag_color_mapping.items():\n",
    "        # Regex to find the tag and replace it with the same tag having a style attribute\n",
    "        text = re.sub(\n",
    "            f'<{tag}>(.*?)</{tag}>',\n",
    "            f'<{tag} style=\"background-color: {color};\">\\\\1</{tag}>',\n",
    "            text,\n",
    "            flags=re.DOTALL\n",
    "        )\n",
    "    return text\n",
    "\n",
    "\n",
    "def parse_csv_file(file_path):\n",
    "    \"\"\"\n",
    "    Parses the input CSV file and extracts questions and their corresponding answers.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input CSV file.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (question, answer_text).\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            question = row.get('question', 'No question found.').strip()\n",
    "            answer_text = row.get('answer', 'No answer found.').strip()\n",
    "            qa_pairs.append((question, answer_text))\n",
    "    return qa_pairs\n",
    "\n",
    "\n",
    "def create_highlight_html(qa_pairs):\n",
    "    \"\"\"\n",
    "    Creates HTML content with highlighted questions, key facts, answer reasoning, and answers.\n",
    "\n",
    "    Args:\n",
    "        qa_pairs (list of tuples): Each tuple contains (question, answer_text).\n",
    "\n",
    "    Returns:\n",
    "        str: The complete HTML content as a string.\n",
    "    \"\"\"\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Question and Answer Highlights</title>\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "                margin: 20px;\n",
    "                background-color: #f0f0f0;\n",
    "            }\n",
    "            .container {\n",
    "                background-color: #ffffff;\n",
    "                padding: 20px;\n",
    "                margin-bottom: 20px;\n",
    "                border-radius: 8px;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            .question {\n",
    "                font-size: 1.2em;\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .key-facts {\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .key-facts ul {\n",
    "                list-style-type: number;\n",
    "                padding-left: 20px;\n",
    "            }\n",
    "            .key-facts ul li{\n",
    "                margin-bottom: 4px;\n",
    "            }\n",
    "            .answer-reasoning, .final-answer {\n",
    "                margin-bottom: 10px;\n",
    "            }\n",
    "            .highlight {\n",
    "                background-color: #FFFF00; /* Yellow background for visibility */\n",
    "                font-weight: bold; /* Bold text for emphasis */\n",
    "            }\n",
    "            /* Styles for specific facts */\n",
    "            fact_1 {\n",
    "                background-color: yellow;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            fact_2 {\n",
    "                background-color: lightblue;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            fact_3 {\n",
    "                background-color: lightgreen;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            fact_4 {\n",
    "                background-color: lightcoral;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            fact_5 {\n",
    "                background-color: lightcyan;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            fact_6 {\n",
    "                background-color: orange;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "    <h1>Question and Answer Highlights</h1>\n",
    "    \"\"\"\n",
    "    for i, (question, answer_text) in enumerate(qa_pairs, 1):\n",
    "        try:\n",
    "            key_facts, answer_reasoning, final_answer = extract_parts_1(answer_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Cannot extract parts for question {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Convert key_facts list to HTML bullet points with \"Key fact X:\" prefix\n",
    "        if key_facts:\n",
    "            key_facts_html = \"<ul>\\n\"\n",
    "            for fact_number, fact_content in key_facts:\n",
    "                # Apply color to tags in fact_content\n",
    "                highlighted_fact = add_color_to_tags(fact_content)\n",
    "                # Prepend \"Key fact X:\"\n",
    "                key_facts_html += f\"    <li><fact_{fact_number}>{highlighted_fact}</fact_{fact_number}></li>\\n\"\n",
    "            key_facts_html += \"</ul>\"\n",
    "        else:\n",
    "            key_facts_html = \"<p>No key facts available.</p>\"\n",
    "\n",
    "        # Apply color to tags in answer_reasoning and final_answer\n",
    "        highlighted_reasoning = add_color_to_tags(answer_reasoning)\n",
    "        highlighted_final_answer = add_color_to_tags(final_answer)\n",
    "\n",
    "        # Build the HTML structure\n",
    "        html_content += f\"<div class='container'>\"\n",
    "        html_content += f\"<div class='question'><strong>Question:</strong> {question}</div>\"\n",
    "        html_content += f\"<div class='key-facts'><strong>Key Facts:</strong> {key_facts_html}</div>\"\n",
    "        html_content += f\"<div class='answer-reasoning'><strong>Answer Reasoning:</strong> {highlighted_reasoning}</div>\"\n",
    "        html_content += f\"<div class='final-answer'><strong>Answer:</strong> {highlighted_final_answer}</div>\"\n",
    "        html_content += \"</div>\\n\"\n",
    "\n",
    "    # Close the HTML tags\n",
    "    html_content += \"\"\"\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html_content\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_file = '/Users/log/Github/textual_grounding/logan/results/GSM8K/llama/test_grounding_answer_prompt_fs_xml_llama3.1.csv'  # Replace with your input CSV file path\n",
    "    output_file = 'output.html'  # Replace with your desired output HTML file path\n",
    "\n",
    "    # Parse the input CSV file to extract questions and answers\n",
    "    qa_pairs = parse_csv_file(input_file)\n",
    "\n",
    "    # Check if any QA pairs were found\n",
    "    if not qa_pairs:\n",
    "        print(\"No question-answer pairs were found in the input file.\")\n",
    "        return\n",
    "\n",
    "    # Generate the HTML content\n",
    "    html_content = create_highlight_html(qa_pairs)\n",
    "\n",
    "    # Write the HTML content to the output file\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"HTML content has been successfully written to {output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tin - visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_highlight_html_regex(questions, answers):\n",
    "    html_content = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Question and Answer Highlights</title>\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "                margin: 20px;\n",
    "            }\n",
    "            .highlight {\n",
    "                background-color: #FFFF00; /* Yellow background for visibility */\n",
    "                font-weight: bold; /* Bold text for emphasis */\n",
    "            }\n",
    "            .container {\n",
    "                display: flex;\n",
    "                justify-content: space-between;\n",
    "                margin-bottom: 20px;\n",
    "            }\n",
    "            .question, .answer {\n",
    "                flex: 1;\n",
    "                padding: 10px;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "    \"\"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers)):\n",
    "        try:\n",
    "            reformulated_question, extracted_answer = extract_parts_1(answer)\n",
    "        except:\n",
    "            print(\"Can not extract parts...\")\n",
    "            continue\n",
    "        \n",
    "        highlighted_answer = add_color_to_tags(extracted_answer)\n",
    "        highlighted_question = add_color_to_tags(reformulated_question)\n",
    "        \n",
    "        html_content += f\"<div class='container'>\"\n",
    "        html_content += f\"<div class='question'><strong>Question:</strong> {question}</div>\"\n",
    "        html_content += f\"<div class='answer'><strong>Reformulated Question:</strong> {highlighted_question}<br><br><strong>Answer:</strong>{highlighted_answer}</div>\"\n",
    "        html_content += \"</div>\\n\"\n",
    "\n",
    "    # Close the HTML tags\n",
    "    html_content += \"\"\"\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parts_1(text):\n",
    "    # Find the \"Reformatted Question\" and \"Answer\" sections\n",
    "    # question_match = re.search(r\"Reformatted Question:(.*?)\\nAnswer:\", text, re.S)\n",
    "    # answer_match = re.search(r\"Answer:(.*)\", text, re.S)\n",
    "    question_match = re.search(r\"Reformatted Question:(.*?)\\nAnswer:\", text, re.S)\n",
    "    answer_match = re.search(r\"Answer:(.*)\", text, re.S)\n",
    "\n",
    "    # Extracting text for each part\n",
    "    if question_match:\n",
    "        question_text = question_match.group(1).strip()\n",
    "    else:\n",
    "        question_match = re.search(r\"Reformatted Question:(.*?)Answer:\", text, re.S)\n",
    "        answer_match = re.search(r\"Answer:(.*)\", text, re.S)\n",
    "        \n",
    "        if question_match:\n",
    "            question_text = question_match.group(1).strip()\n",
    "        else:\n",
    "            question_text = \"Question not found\"\n",
    "    \n",
    "    if answer_match:\n",
    "        answer_text = answer_match.group(1).strip()\n",
    "    else:\n",
    "        answer_text = \"Answer not found\"\n",
    "\n",
    "    return question_text, answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_html_path = f\"question_answer_highlights_prompt_{prompt_type}_{llm_model}.html\"\n",
    "# df_path = f'logan/results/{dataset}/llama/test_grounding_answer_prompt_{prompt_type}_{llm_model}.csv'\n",
    "df_path = '/Users/log/Github/textual_grounding/logan/results/GSM8K/llama/test_grounding_answer_prompt_fs_xml_llama3.1.csv'\n",
    "if prompt_type in [\"fs\", \"fs_inst\"]:\n",
    "    prefix = 'The answer is'\n",
    "elif prompt_type == \"zs\":\n",
    "    prefix = 'Final answer:'\n",
    "\n",
    "df = pd.read_csv(df_path)\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()\n",
    "\n",
    "# create html\n",
    "html_content = create_highlight_html_regex(questions, answers)\n",
    "\n",
    "# Optionally write to an HTML file\n",
    "with open(save_html_path, \"w\") as file:\n",
    "    file.write(html_content)\n",
    "    print(f\"succesfully wrote to {save_html_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
